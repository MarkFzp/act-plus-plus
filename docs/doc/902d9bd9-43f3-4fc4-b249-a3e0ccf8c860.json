{
    "summary": "The code creates a function for a bi-manual robot environment, initializes tasks and robots, sets rewards, uses physics simulation, and derives the \"InsertionEETask\" class. It assigns fixed rewards of 4 to contact scenarios in peg insertion tasks.",
    "details": [
        {
            "comment": "The code imports necessary libraries and defines a function `make_ee_sim_env(task_name)` that creates an environment for simulated robot bi-manual manipulation with end-effector control. The action space includes left and right arm pose, along with gripper positions for both arms.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":0-25",
            "content": "import numpy as np\nimport collections\nimport os\nfrom constants import DT, XML_DIR, START_ARM_POSE\nfrom constants import PUPPET_GRIPPER_POSITION_CLOSE\nfrom constants import PUPPET_GRIPPER_POSITION_UNNORMALIZE_FN\nfrom constants import PUPPET_GRIPPER_POSITION_NORMALIZE_FN\nfrom constants import PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN\nfrom utils import sample_box_pose, sample_insertion_pose\nfrom dm_control import mujoco\nfrom dm_control.rl import control\nfrom dm_control.suite import base\nimport IPython\ne = IPython.embed\ndef make_ee_sim_env(task_name):\n    \"\"\"\n    Environment for simulated robot bi-manual manipulation, with end-effector control.\n    Action space:      [left_arm_pose (7),             # position and quaternion for end effector\n                        left_gripper_positions (1),    # normalized gripper position (0: close, 1: open)\n                        right_arm_pose (7),            # position and quaternion for end effector\n                        right_gripper_positions (1),]  # normalized gripper position (0: close, 1: open)"
        },
        {
            "comment": "The code defines the observation space for a simulation environment, including absolute joint positions and velocities for both left and right arms, gripper positions and velocities, and image data from a camera. This is likely used in a robotics control algorithm or reinforcement learning task. If \"sim_transfer_cube\" is in the task name, it suggests that the simulation involves transferring an object (possibly a cube) between the left and right arms.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":27-37",
            "content": "    Observation space: {\"qpos\": Concat[ left_arm_qpos (6),         # absolute joint position\n                                        left_gripper_position (1),  # normalized gripper position (0: close, 1: open)\n                                        right_arm_qpos (6),         # absolute joint position\n                                        right_gripper_qpos (1)]     # normalized gripper position (0: close, 1: open)\n                        \"qvel\": Concat[ left_arm_qvel (6),         # absolute joint velocity (rad)\n                                        left_gripper_velocity (1),  # normalized gripper velocity (pos: opening, neg: closing)\n                                        right_arm_qvel (6),         # absolute joint velocity (rad)\n                                        right_gripper_qvel (1)]     # normalized gripper velocity (pos: opening, neg: closing)\n                        \"images\": {\"main\": (480x640x3)}        # h, w, c, dtype='uint8'\n    \"\"\"\n    if 'sim_transfer_cube' in task_name:"
        },
        {
            "comment": "This code initializes an environment for a bimanual ViperX EE task, possibly either cube transfer or insertion. It joins the XML file path with the directory and loads the physics from the XML file. Then, it instantiates the specific task (TransferCubeEETask or InsertionEETask) based on the task name. Finally, it creates an environment object using the physics and task, setting the time limit, control timestep, and other options. If no matching task name is found, it raises a NotImplementedError. The BimanualViperXEETask class initializes the base task with an optional random parameter.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":38-60",
            "content": "        xml_path = os.path.join(XML_DIR, f'bimanual_viperx_ee_transfer_cube.xml')\n        physics = mujoco.Physics.from_xml_path(xml_path)\n        task = TransferCubeEETask(random=False)\n        env = control.Environment(physics, task, time_limit=20, control_timestep=DT,\n                                  n_sub_steps=None, flat_observation=False)\n    elif 'sim_insertion' in task_name:\n        xml_path = os.path.join(XML_DIR, f'bimanual_viperx_ee_insertion.xml')\n        physics = mujoco.Physics.from_xml_path(xml_path)\n        task = InsertionEETask(random=False)\n        env = control.Environment(physics, task, time_limit=20, control_timestep=DT,\n                                  n_sub_steps=None, flat_observation=False)\n    else:\n        raise NotImplementedError\n    return env\nclass BimanualViperXEETask(base.Task):\n    def __init__(self, random=None):\n        super().__init__(random=random)\n    def before_step(self, action, physics):\n        a_len = len(action) // 2\n        action_left = action[:a_len]\n        action_right = action[a_len:]"
        },
        {
            "comment": "This code initializes robots in the environment by resetting joint positions and setting mocap (motion capture) position and quaternion for left and right arms. It also sets gripper control values using a provided function, ensuring proper alignment between end effector and mocap data.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":62-83",
            "content": "        # set mocap position and quat\n        # left\n        np.copyto(physics.data.mocap_pos[0], action_left[:3])\n        np.copyto(physics.data.mocap_quat[0], action_left[3:7])\n        # right\n        np.copyto(physics.data.mocap_pos[1], action_right[:3])\n        np.copyto(physics.data.mocap_quat[1], action_right[3:7])\n        # set gripper\n        g_left_ctrl = PUPPET_GRIPPER_POSITION_UNNORMALIZE_FN(action_left[7])\n        g_right_ctrl = PUPPET_GRIPPER_POSITION_UNNORMALIZE_FN(action_right[7])\n        np.copyto(physics.data.ctrl, np.array([g_left_ctrl, -g_left_ctrl, g_right_ctrl, -g_right_ctrl]))\n    def initialize_robots(self, physics):\n        # reset joint position\n        physics.named.data.qpos[:16] = START_ARM_POSE\n        # reset mocap to align with end effector\n        # to obtain these numbers:\n        # (1) make an ee_sim env and reset to the same start_pose\n        # (2) get env._physics.named.data.xpos['vx300s_left/gripper_link']\n        #     get env._physics.named.data.xquat['vx300s_left/gripper_link']"
        },
        {
            "comment": "This code segment sets the initial positions, orientations, and gripper control for both left and right sides of a simulated robot arm. It also defines an initialize_episode function and a get_qpos static method in a class inheriting from an unspecified base class. The left and right positions are set using numpy's copyto() function, and the gripper control is initialized to close position.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":84-109",
            "content": "        #     repeat the same for right side\n        np.copyto(physics.data.mocap_pos[0], [-0.31718881+0.1, 0.5, 0.29525084])\n        np.copyto(physics.data.mocap_quat[0], [1, 0, 0, 0])\n        # right\n        np.copyto(physics.data.mocap_pos[1], np.array([0.31718881-0.1, 0.49999888, 0.29525084]))\n        np.copyto(physics.data.mocap_quat[1],  [1, 0, 0, 0])\n        # reset gripper control\n        close_gripper_control = np.array([\n            PUPPET_GRIPPER_POSITION_CLOSE,\n            -PUPPET_GRIPPER_POSITION_CLOSE,\n            PUPPET_GRIPPER_POSITION_CLOSE,\n            -PUPPET_GRIPPER_POSITION_CLOSE,\n        ])\n        np.copyto(physics.data.ctrl, close_gripper_control)\n    def initialize_episode(self, physics):\n        \"\"\"Sets the state of the environment at the start of each episode.\"\"\"\n        super().initialize_episode(physics)\n    @staticmethod\n    def get_qpos(physics):\n        qpos_raw = physics.data.qpos.copy()\n        left_qpos_raw = qpos_raw[:8]\n        right_qpos_raw = qpos_raw[8:16]\n        left_arm_qpos = left_qpos_raw[:6]"
        },
        {
            "comment": "The code defines functions to extract joint positions, velocities, and environment state from physics data. It normalizes gripper position and velocity values using the respective PUPPET_*_NORMALIZE_FN functions. The get_observation function combines left and right arm joint positions, gripper positions, and velocities into a concatenated numpy array. The code also includes an unimplemented get_env_state method.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":110-132",
            "content": "        right_arm_qpos = right_qpos_raw[:6]\n        left_gripper_qpos = [PUPPET_GRIPPER_POSITION_NORMALIZE_FN(left_qpos_raw[6])]\n        right_gripper_qpos = [PUPPET_GRIPPER_POSITION_NORMALIZE_FN(right_qpos_raw[6])]\n        return np.concatenate([left_arm_qpos, left_gripper_qpos, right_arm_qpos, right_gripper_qpos])\n    @staticmethod\n    def get_qvel(physics):\n        qvel_raw = physics.data.qvel.copy()\n        left_qvel_raw = qvel_raw[:8]\n        right_qvel_raw = qvel_raw[8:16]\n        left_arm_qvel = left_qvel_raw[:6]\n        right_arm_qvel = right_qvel_raw[:6]\n        left_gripper_qvel = [PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN(left_qvel_raw[6])]\n        right_gripper_qvel = [PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN(right_qvel_raw[6])]\n        return np.concatenate([left_arm_qvel, left_gripper_qvel, right_arm_qvel, right_gripper_qvel])\n    @staticmethod\n    def get_env_state(physics):\n        raise NotImplementedError\n    def get_observation(self, physics):\n        # note: it is important to do .copy()\n        obs = collections.OrderedDict()"
        },
        {
            "comment": "This code defines a class for an environment in which a robot arm needs to manipulate a cube. The environment is initialized and returns observation (obs) containing information about the state of the robot, images from different camera perspectives, starting pose of the left and right mocap hands, and gripper control data. It also defines a reward function that needs to be implemented for specific tasks within this environment. This class inherits from BimanualViperXEETask which is likely another class for similar environments.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":133-154",
            "content": "        obs['qpos'] = self.get_qpos(physics)\n        obs['qvel'] = self.get_qvel(physics)\n        obs['env_state'] = self.get_env_state(physics)\n        obs['images'] = dict()\n        obs['images']['top'] = physics.render(height=480, width=640, camera_id='top')\n        # obs['images']['angle'] = physics.render(height=480, width=640, camera_id='angle')\n        # obs['images']['vis'] = physics.render(height=480, width=640, camera_id='front_close')\n        # used in scripted policy to obtain starting pose\n        obs['mocap_pose_left'] = np.concatenate([physics.data.mocap_pos[0], physics.data.mocap_quat[0]]).copy()\n        obs['mocap_pose_right'] = np.concatenate([physics.data.mocap_pos[1], physics.data.mocap_quat[1]]).copy()\n        # used when replaying joint trajectory\n        obs['gripper_ctrl'] = physics.data.ctrl.copy()\n        return obs\n    def get_reward(self, physics):\n        raise NotImplementedError\nclass TransferCubeEETask(BimanualViperXEETask):\n    def __init__(self, random=None):\n        super().__init__(random=random)"
        },
        {
            "comment": "The code initializes the environment for each episode, randomizes the box position, and defines methods to get the environment state and reward in a physics simulation. The maximum reward is set to 4.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":155-180",
            "content": "        self.max_reward = 4\n    def initialize_episode(self, physics):\n        \"\"\"Sets the state of the environment at the start of each episode.\"\"\"\n        self.initialize_robots(physics)\n        # randomize box position\n        cube_pose = sample_box_pose()\n        box_start_idx = physics.model.name2id('red_box_joint', 'joint')\n        np.copyto(physics.data.qpos[box_start_idx : box_start_idx + 7], cube_pose)\n        # print(f\"randomized cube position to {cube_position}\")\n        super().initialize_episode(physics)\n    @staticmethod\n    def get_env_state(physics):\n        env_state = physics.data.qpos.copy()[16:]\n        return env_state\n    def get_reward(self, physics):\n        # return whether left gripper is holding the box\n        all_contact_pairs = []\n        for i_contact in range(physics.data.ncon):\n            id_geom_1 = physics.data.contact[i_contact].geom1\n            id_geom_2 = physics.data.contact[i_contact].geom2\n            name_geom_1 = physics.model.id2name(id_geom_1, 'geom')\n            name_geom_2 = physics.model.id2name(id_geom_2, 'geom')"
        },
        {
            "comment": "The code defines a class called \"InsertionEETask\" which inherits from the \"BimanualViperXEETask\". This task seems to be related to manipulating objects in a simulation environment. It initializes the state of the environment at the start of each episode by calling the \"initialize_robots()\" function. The code checks for different contact scenarios and assigns corresponding rewards, ranging from 0 to 4. The maximum reward is set to 4.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":181-207",
            "content": "            contact_pair = (name_geom_1, name_geom_2)\n            all_contact_pairs.append(contact_pair)\n        touch_left_gripper = (\"red_box\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs\n        touch_right_gripper = (\"red_box\", \"vx300s_right/10_right_gripper_finger\") in all_contact_pairs\n        touch_table = (\"red_box\", \"table\") in all_contact_pairs\n        reward = 0\n        if touch_right_gripper:\n            reward = 1\n        if touch_right_gripper and not touch_table: # lifted\n            reward = 2\n        if touch_left_gripper: # attempted transfer\n            reward = 3\n        if touch_left_gripper and not touch_table: # successful transfer\n            reward = 4\n        return reward\nclass InsertionEETask(BimanualViperXEETask):\n    def __init__(self, random=None):\n        super().__init__(random=random)\n        self.max_reward = 4\n    def initialize_episode(self, physics):\n        \"\"\"Sets the state of the environment at the start of each episode.\"\"\"\n        self.initialize_robots(physics)"
        },
        {
            "comment": "This code initializes the episode by randomizing the peg and socket positions in a physics simulation. It converts joint IDs to indices, sets the new positions for the peg and socket using numpy copyto function, and calls the superclass' initialize_episode method. It also includes a get_env_state function which returns the environment state from the physics data qpos array excluding the first 16 elements (robot qpos), and a placeholder get_reward function that will return whether the peg touches the pin in all contact pairs.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":208-231",
            "content": "        # randomize peg and socket position\n        peg_pose, socket_pose = sample_insertion_pose()\n        id2index = lambda j_id: 16 + (j_id - 16) * 7 # first 16 is robot qpos, 7 is pose dim # hacky\n        peg_start_id = physics.model.name2id('red_peg_joint', 'joint')\n        peg_start_idx = id2index(peg_start_id)\n        np.copyto(physics.data.qpos[peg_start_idx : peg_start_idx + 7], peg_pose)\n        # print(f\"randomized cube position to {cube_position}\")\n        socket_start_id = physics.model.name2id('blue_socket_joint', 'joint')\n        socket_start_idx = id2index(socket_start_id)\n        np.copyto(physics.data.qpos[socket_start_idx : socket_start_idx + 7], socket_pose)\n        # print(f\"randomized cube position to {cube_position}\")\n        super().initialize_episode(physics)\n    @staticmethod\n    def get_env_state(physics):\n        env_state = physics.data.qpos.copy()[16:]\n        return env_state\n    def get_reward(self, physics):\n        # return whether peg touches the pin\n        all_contact_pairs = []"
        },
        {
            "comment": "This code checks for contact between various objects in a physics simulation. It iterates through all contacts, retrieves the associated geometries and converts their IDs to names. Then, it identifies if a red peg is touching the right gripper, and checks multiple conditions for left gripper and socket-peg interactions with the table.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":232-247",
            "content": "        for i_contact in range(physics.data.ncon):\n            id_geom_1 = physics.data.contact[i_contact].geom1\n            id_geom_2 = physics.data.contact[i_contact].geom2\n            name_geom_1 = physics.model.id2name(id_geom_1, 'geom')\n            name_geom_2 = physics.model.id2name(id_geom_2, 'geom')\n            contact_pair = (name_geom_1, name_geom_2)\n            all_contact_pairs.append(contact_pair)\n        touch_right_gripper = (\"red_peg\", \"vx300s_right/10_right_gripper_finger\") in all_contact_pairs\n        touch_left_gripper = (\"socket-1\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs or \\\n                             (\"socket-2\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs or \\\n                             (\"socket-3\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs or \\\n                             (\"socket-4\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs\n        peg_touch_table = (\"red_peg\", \"table\") in all_contact_pairs\n        socket_touch_table = (\"socket-1\", \"table\") in all_contact_pairs or \\"
        },
        {
            "comment": "This code determines the reward based on contact pairs. It checks for touching \"socket-1\" to \"table\", \"socket-2\" to \"table\", etc. It also checks if any of the pegs are touching a socket, table or both, and if the red peg is touching the pin. The reward is given based on these conditions. If both gripper touch something, it gives a reward of 1. If both gripper touches nothing but grasp something, reward is 2. If peg touches socket but not table, reward is 3. Finally, if any peg touches the pin, it's considered as successful insertion.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":248-264",
            "content": "                             (\"socket-2\", \"table\") in all_contact_pairs or \\\n                             (\"socket-3\", \"table\") in all_contact_pairs or \\\n                             (\"socket-4\", \"table\") in all_contact_pairs\n        peg_touch_socket = (\"red_peg\", \"socket-1\") in all_contact_pairs or \\\n                           (\"red_peg\", \"socket-2\") in all_contact_pairs or \\\n                           (\"red_peg\", \"socket-3\") in all_contact_pairs or \\\n                           (\"red_peg\", \"socket-4\") in all_contact_pairs\n        pin_touched = (\"red_peg\", \"pin\") in all_contact_pairs\n        reward = 0\n        if touch_left_gripper and touch_right_gripper: # touch both\n            reward = 1\n        if touch_left_gripper and touch_right_gripper and (not peg_touch_table) and (not socket_touch_table): # grasp both\n            reward = 2\n        if peg_touch_socket and (not peg_touch_table) and (not socket_touch_table): # peg and socket touching\n            reward = 3\n        if pin_touched: # successful insertion"
        },
        {
            "comment": "This code snippet assigns a fixed reward value of 4 and then returns it. This suggests the reward is determined solely by this function without any external factors influencing it.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/ee_sim_env.py\":265-266",
            "content": "            reward = 4\n        return reward"
        }
    ]
}