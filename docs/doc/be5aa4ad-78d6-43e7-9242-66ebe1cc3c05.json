{
    "summary": "The code imports libraries, initializes policy and environment, iterates over time steps, takes actions, updates state, determines success, and evaluates simulation episodes, storing data in an HDF5 file for visualization or analysis. It also creates datasets from camera images, qpos, and actions.",
    "details": [
        {
            "comment": "The code imports necessary libraries, defines the main function to generate demonstration data in simulation. It first rolls out policy in ee_sim_env and obtains joint trajectory, then replaces gripper joint positions with commanded positions. Finally, it replay joint trajectory in sim_env and record observations for each episode before saving the dataset.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/record_sim_episodes.py\":0-32",
            "content": "import time\nimport os\nimport numpy as np\nimport argparse\nimport matplotlib.pyplot as plt\nimport h5py\nfrom constants import PUPPET_GRIPPER_POSITION_NORMALIZE_FN, SIM_TASK_CONFIGS\nfrom ee_sim_env import make_ee_sim_env\nfrom sim_env import make_sim_env, BOX_POSE\nfrom scripted_policy import PickAndTransferPolicy, InsertionPolicy\nimport IPython\ne = IPython.embed\ndef main(args):\n    \"\"\"\n    Generate demonstration data in simulation.\n    First rollout the policy (defined in ee space) in ee_sim_env. Obtain the joint trajectory.\n    Replace the gripper joint positions with the commanded joint position.\n    Replay this joint trajectory (as action sequence) in sim_env, and record all observations.\n    Save this episode of data, and continue to next episode of data collection.\n    \"\"\"\n    task_name = args['task_name']\n    dataset_dir = args['dataset_dir']\n    num_episodes = args['num_episodes']\n    onscreen_render = args['onscreen_render']\n    inject_noise = False\n    render_cam_name = 'top'\n    if not os.path.isdir(dataset_dir):"
        },
        {
            "comment": "This code snippet is creating a new directory for the dataset, setting up the episode length and camera names based on the task name, and then initializing the policy class depending on the task. It also creates an empty list for success and starts a loop for each episode where it sets up the environment, resets the environment, creates an episode list with the first observation, initializes the policy, and then starts another loop to iterate through steps in each episode.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/record_sim_episodes.py\":33-60",
            "content": "        os.makedirs(dataset_dir, exist_ok=True)\n    episode_len = SIM_TASK_CONFIGS[task_name]['episode_len']\n    camera_names = SIM_TASK_CONFIGS[task_name]['camera_names']\n    if task_name == 'sim_transfer_cube_scripted':\n        policy_cls = PickAndTransferPolicy\n    elif task_name == 'sim_insertion_scripted':\n        policy_cls = InsertionPolicy\n    elif task_name == 'sim_transfer_cube_scripted_mirror':\n        policy_cls = PickAndTransferPolicy\n    else:\n        raise NotImplementedError\n    success = []\n    for episode_idx in range(num_episodes):\n        print(f'{episode_idx=}')\n        print('Rollout out EE space scripted policy')\n        # setup the environment\n        env = make_ee_sim_env(task_name)\n        ts = env.reset()\n        episode = [ts]\n        policy = policy_cls(inject_noise)\n        # setup plotting\n        if onscreen_render:\n            ax = plt.subplot()\n            plt_img = ax.imshow(ts.observation['images'][render_cam_name])\n            plt.ion()\n        for step in range(episode_len):"
        },
        {
            "comment": "This code is iterating over each time step in the episode, taking actions based on a policy, updating the state, and appending the state to the episode list. It also renders images for each state if the onscreen_render flag is set. It calculates the episode return and maximum reward, then prints whether the episode was successful or not. Finally, it extracts joint and gripper control trajectories from the episode and applies normalization to gripper positions.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/record_sim_episodes.py\":61-83",
            "content": "            action = policy(ts)\n            ts = env.step(action)\n            episode.append(ts)\n            if onscreen_render:\n                plt_img.set_data(ts.observation['images'][render_cam_name])\n                plt.pause(0.002)\n        plt.close()\n        episode_return = np.sum([ts.reward for ts in episode[1:]])\n        episode_max_reward = np.max([ts.reward for ts in episode[1:]])\n        if episode_max_reward == env.task.max_reward:\n            print(f\"{episode_idx=} Successful, {episode_return=}\")\n        else:\n            print(f\"{episode_idx=} Failed\")\n        joint_traj = [ts.observation['qpos'] for ts in episode]\n        # replace gripper pose with gripper control\n        gripper_ctrl_traj = [ts.observation['gripper_ctrl'] for ts in episode]\n        for joint, ctrl in zip(joint_traj, gripper_ctrl_traj):\n            left_ctrl = PUPPET_GRIPPER_POSITION_NORMALIZE_FN(ctrl[0])\n            right_ctrl = PUPPET_GRIPPER_POSITION_NORMALIZE_FN(ctrl[2])\n            joint[6] = left_ctrl\n            joint[6+7] = right_ctrl"
        },
        {
            "comment": "This code is replaying joint commands from a previous episode. It first saves the initial box pose, clears unused variables, sets up the environment, and resets it. Then, for each joint command in the trajectory, it performs an action in the environment and appends the new state to the episode_replay list. If onscreen_render is True, it updates a plot with the current observation image. Finally, it calculates the total reward from the episode and stores it as episode_return.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/record_sim_episodes.py\":85-112",
            "content": "        subtask_info = episode[0].observation['env_state'].copy() # box pose at step 0\n        # clear unused variables\n        del env\n        del episode\n        del policy\n        # setup the environment\n        print('Replaying joint commands')\n        env = make_sim_env(task_name)\n        BOX_POSE[0] = subtask_info # make sure the sim_env has the same object configurations as ee_sim_env\n        ts = env.reset()\n        episode_replay = [ts]\n        # setup plotting\n        if onscreen_render:\n            ax = plt.subplot()\n            plt_img = ax.imshow(ts.observation['images'][render_cam_name])\n            plt.ion()\n        for t in range(len(joint_traj)): # note: this will increase episode length by 1\n            action = joint_traj[t]\n            ts = env.step(action)\n            episode_replay.append(ts)\n            if onscreen_render:\n                plt_img.set_data(ts.observation['images'][render_cam_name])\n                plt.pause(0.02)\n        episode_return = np.sum([ts.reward for ts in episode_replay[1:]])"
        },
        {
            "comment": "This code measures the success of each episode in a simulation by checking if the maximum reward reached the maximum possible reward. If it did, the episode is considered successful and printed as such; otherwise, it's considered a failure. The code also collects observations and actions into a data dictionary for potential visualization or analysis purposes.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/record_sim_episodes.py\":113-144",
            "content": "        episode_max_reward = np.max([ts.reward for ts in episode_replay[1:]])\n        if episode_max_reward == env.task.max_reward:\n            success.append(1)\n            print(f\"{episode_idx=} Successful, {episode_return=}\")\n        else:\n            success.append(0)\n            print(f\"{episode_idx=} Failed\")\n        plt.close()\n        \"\"\"\n        For each timestep:\n        observations\n        - images\n            - each_cam_name     (480, 640, 3) 'uint8'\n        - qpos                  (14,)         'float64'\n        - qvel                  (14,)         'float64'\n        action                  (14,)         'float64'\n        \"\"\"\n        data_dict = {\n            '/observations/qpos': [],\n            '/observations/qvel': [],\n            '/action': [],\n        }\n        for cam_name in camera_names:\n            data_dict[f'/observations/images/{cam_name}'] = []\n        # because the replaying, there will be eps_len + 1 actions and eps_len + 2 timesteps\n        # truncate here to be consistent\n        joint_traj = joint_traj[:-1]"
        },
        {
            "comment": "This code segment is part of a function that processes episode data from a simulation and saves it as an HDF5 file. It extracts observations, actions, and camera images from the episode replay and stores them in the dictionary \"data_dict\". After processing all timesteps, it creates an HDF5 file with the episode data, including attributes and groups for observations and images.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/record_sim_episodes.py\":145-166",
            "content": "        episode_replay = episode_replay[:-1]\n        # len(joint_traj) i.e. actions: max_timesteps\n        # len(episode_replay) i.e. time steps: max_timesteps + 1\n        max_timesteps = len(joint_traj)\n        while joint_traj:\n            action = joint_traj.pop(0)\n            ts = episode_replay.pop(0)\n            data_dict['/observations/qpos'].append(ts.observation['qpos'])\n            data_dict['/observations/qvel'].append(ts.observation['qvel'])\n            data_dict['/action'].append(action)\n            for cam_name in camera_names:\n                data_dict[f'/observations/images/{cam_name}'].append(ts.observation['images'][cam_name])\n        # HDF5\n        t0 = time.time()\n        dataset_path = os.path.join(dataset_dir, f'episode_{episode_idx}')\n        with h5py.File(dataset_path + '.hdf5', 'w', rdcc_nbytes=1024 ** 2 * 2) as root:\n            root.attrs['sim'] = True\n            obs = root.create_group('observations')\n            image = obs.create_group('images')\n            for cam_name in camera_names:"
        },
        {
            "comment": "This code creates datasets for camera images, qpos, qvel, and actions in a specific order. It then assigns the array values to corresponding names within the root dataset. Finally, it provides statistics on the saving time, saved location, and success rate of the task. The code assumes 'max_timesteps', 'data_dict', 'cam_name' and 'obs' are predefined variables.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/record_sim_episodes.py\":167-185",
            "content": "                _ = image.create_dataset(cam_name, (max_timesteps, 480, 640, 3), dtype='uint8',\n                                         chunks=(1, 480, 640, 3), )\n            # compression='gzip',compression_opts=2,)\n            # compression=32001, compression_opts=(0, 0, 0, 0, 9, 1, 1), shuffle=False)\n            qpos = obs.create_dataset('qpos', (max_timesteps, 14))\n            qvel = obs.create_dataset('qvel', (max_timesteps, 14))\n            action = root.create_dataset('action', (max_timesteps, 14))\n            for name, array in data_dict.items():\n                root[name][...] = array\n        print(f'Saving: {time.time() - t0:.1f} secs\\n')\n    print(f'Saved to {dataset_dir}')\n    print(f'Success: {np.sum(success)} / {len(success)}')\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--task_name', action='store', type=str, help='task_name', required=True)\n    parser.add_argument('--dataset_dir', action='store', type=str, help='dataset saving dir', required=True)"
        },
        {
            "comment": "The code above adds command line arguments for the number of episodes and on-screen rendering to a parser. The 'num_episodes' argument is of type int, required=False, and helps specify the number of episodes to run. The 'onscreen_render' argument, when set to true, enables on-screen rendering during game playback. The main function takes the arguments parsed by the parser object to execute the program.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/record_sim_episodes.py\":186-189",
            "content": "    parser.add_argument('--num_episodes', action='store', type=int, help='num_episodes', required=False)\n    parser.add_argument('--onscreen_render', action='store_true')\n    main(vars(parser.parse_args()))"
        }
    ]
}