{
    "summary": "The function `calculate_nearest_neighbors()` computes nearest neighbor losses and is used to select the optimal value of 'k' for a dataset, plotting and saving the best loss. User inputs: dataset directory, checkpoint directory.",
    "details": [
        {
            "comment": "Code imports necessary libraries and defines a function `calculate_nearest_neighbors()` that takes in query inputs, target values, support inputs, and support targets as well as a maximum value of K. It then calculates the pairwise distances between the query inputs and support inputs, sorts them, and calculates weights for the nearest neighbors using softmax. Finally, it computes errors by weighting the support targets based on these calculated weights.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_select_k.py\":0-30",
            "content": "import torch\nimport torch.nn.functional as F\nimport numpy as np\nimport h5py\nimport pathlib\nimport os\nimport argparse\nimport matplotlib.pyplot as plt\nimport IPython\ne = IPython.embed\n# modified from https://github.com/jyopari/VINN/blob/main/nearest-neighbor-eval/handle_nn.ipynb\ndef calculate_nearest_neighbors(query_inputs, query_targets, support_inputs, support_targets, max_k):\n    with torch.no_grad():\n        pairwise_dist = []\n        for q_in in query_inputs:\n            diff = support_inputs - q_in.unsqueeze(0)\n            dist = torch.norm(diff, dim=1)\n            pairwise_dist.append(dist)\n        pairwise_dist = torch.stack(pairwise_dist)\n        sorted_dist, index = torch.sort(pairwise_dist, dim=1) # sort the support axis\n        permuted_support_targets = support_targets[index]\n        errors = []\n        for k in range(1, max_k):\n            topk_dist = pairwise_dist[:, :k]\n            topk_support_targets = permuted_support_targets[:, :k]\n            weights = F.softmax(-topk_dist, dim=1)\n            weighted_support_targets = weights.unsqueeze(2) * topk_support_targets"
        },
        {
            "comment": "This code reads episode indices from a specified directory, sorts them, and asserts there are no gaps. It then determines a validation split of 80% for training data. The code loads the training data into list X.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_select_k.py\":31-65",
            "content": "            prediction = torch.sum(weighted_support_targets, dim=1)\n            error = F.mse_loss(prediction, query_targets)\n            errors.append(error)\n        return errors\ndef chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\ndef main(args):\n    # TODO ######################\n    dataset_dir = args['dataset_dir']\n    ckpt_dir = args['ckpt_dir']\n    seed = 0\n    max_k = 400\n    batch_size = 100\n    # TODO ######################\n    repr_type = 'byol'\n    if 'cotrain' in ckpt_dir:\n        repr_type += '_cotrain'\n    e() # make sure!\n    if not os.path.isdir(ckpt_dir):\n        os.makedirs(ckpt_dir)\n    episode_idxs = [int(name.split('_')[1].split('.')[0]) for name in os.listdir(dataset_dir) if ('.hdf5' in name) and ('features' not in name)]\n    episode_idxs.sort()\n    assert len(episode_idxs) == episode_idxs[-1] + 1 # no holes\n    num_episodes = len(episode_idxs)\n    val_split = int(num_episodes * 0.8)\n    # load train data\n    X = []"
        },
        {
            "comment": "This code loads data from HDF5 files and concatenates it for training. It reads action labels and camera features for each episode, then combines them into a single feature matrix (X) and action label matrix (Y). The code also prints the shape of the feature matrices.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_select_k.py\":66-93",
            "content": "    Y = []\n    for episode_id in range(0, val_split):\n        dataset_path = os.path.join(dataset_dir, f'episode_{episode_id}.hdf5')\n        with h5py.File(dataset_path, 'r') as root:\n            action = root['/action'][:]\n            camera_names = list(root[f'/observations/images/'].keys())\n        all_cam_feature = []\n        feature_dataset_path = os.path.join(dataset_dir, f'{repr_type}_features_seed{seed}_episode_{episode_id}.hdf5')\n        with h5py.File(feature_dataset_path, 'r') as root:\n            for cam_name in camera_names:\n                cam_feature = root[f'/features/{cam_name}'][:]\n                all_cam_feature.append(cam_feature)\n        cam_feature = np.concatenate(all_cam_feature, axis=1)\n        X.append(cam_feature)\n        Y.append(action)\n    X = np.concatenate(X)\n    Y = np.concatenate(Y)\n    train_inputs = torch.from_numpy(X).cuda()\n    train_targets = torch.from_numpy(Y).cuda()\n    print(f'All features: {train_inputs.shape}')\n    # load test data\n    X = []\n    Y = []\n    for episode_id in range(val_split, num_episodes):"
        },
        {
            "comment": "This code loads data from multiple HDF5 files, concatenates camera features into a single feature matrix (X), and associates corresponding actions as targets (Y). It then prepares the data for training by converting to PyTorch tensors and computing nearest neighbor losses using a custom function. The resulting losses are stored in val_losses list.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_select_k.py\":94-117",
            "content": "        dataset_path = os.path.join(dataset_dir, f'episode_{episode_id}.hdf5')\n        with h5py.File(dataset_path, 'r') as root:\n            action = root['/action'][:]\n        all_cam_feature = []\n        feature_dataset_path = os.path.join(dataset_dir, f'{repr_type}_features_seed{seed}_episode_{episode_id}.hdf5')\n        with h5py.File(feature_dataset_path, 'r') as root:\n            for cam_name in camera_names:\n                cam_feature = root[f'/features/{cam_name}'][:]\n                all_cam_feature.append(cam_feature)\n        cam_feature = np.concatenate(all_cam_feature, axis=1)\n        X.append(cam_feature)\n        Y.append(action)\n    X = np.concatenate(X)\n    Y = np.concatenate(Y)\n    val_inputs = torch.from_numpy(X).cuda()\n    val_targets = torch.from_numpy(Y).cuda()\n    val_losses = []\n    for inputs, targets in zip(chunks(val_inputs, batch_size), chunks(val_targets, batch_size)):\n        val_loss = calculate_nearest_neighbors(inputs, targets, train_inputs, train_targets, max_k)\n        val_loss = torch.stack(val_loss)"
        },
        {
            "comment": "This code is used to select the optimal value of 'k' for a dataset. It calculates the validation loss for different values of 'k', plots the losses, and saves the best loss in an image file. The user needs to provide the directory path for the dataset and the checkpoint directory as input arguments.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_select_k.py\":118-133",
            "content": "        val_losses.append(val_loss)\n    val_losses = torch.mean(torch.stack(val_losses), dim=0)\n    val_loss = val_losses\n    val_loss = torch.tensor(val_loss).cpu().numpy()\n    print(f'min val loss of {np.min(val_loss)} at k={np.argmin(val_loss)}')\n    plt.plot(np.arange(1, max_k), val_loss)\n    plt.savefig(os.path.join(ckpt_dir, f'k_select-seed{seed}.png'))\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--dataset_dir', action='store', type=str, help='The text to parse.', required=True)\n    parser.add_argument('--ckpt_dir', action='store', type=str, help='The text to parse.', required=True)\n    main(vars(parser.parse_args()))"
        }
    ]
}