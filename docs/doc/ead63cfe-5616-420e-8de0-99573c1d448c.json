{
    "summary": "The code imports libraries, loads data, processes episode information, scales actions, compresses images with JPEG quality 50, and saves in HDF5 format. It generates datasets for image variables and populates root dataset from data_dict.",
    "details": [
        {
            "comment": "This code imports necessary libraries and defines constants for a robotics data processing script. It loads data from .hdf5 files, including robot joint positions and velocities, as well as actions performed by the robot.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/postprocess_episodes.py\":0-32",
            "content": "import os\nimport numpy as np\nimport cv2\nimport h5py\nimport argparse\nimport time\nfrom visualize_episodes import visualize_joints, visualize_timestamp, save_videos\nimport matplotlib.pyplot as plt\nfrom constants import DT\nimport IPython\ne = IPython.embed\nJOINT_NAMES = [\"waist\", \"shoulder\", \"elbow\", \"forearm_roll\", \"wrist_angle\", \"wrist_rotate\"]\nSTATE_NAMES = JOINT_NAMES + [\"gripper\"]\nMIRROR_STATE_MULTIPLY = np.array([-1, 1, 1, -1, 1, -1, 1]).astype('float32')\nMIRROR_BASE_MULTIPLY = np.array([1, -1]).astype('float32')\ndef load_hdf5(dataset_dir, dataset_name):\n    dataset_path = os.path.join(dataset_dir, dataset_name + '.hdf5')\n    if not os.path.isfile(dataset_path):\n        print(f'Dataset does not exist at \\n{dataset_path}\\n')\n        exit()\n    with h5py.File(dataset_path, 'r') as root:\n        is_sim = root.attrs['sim']\n        compressed = root.attrs.get('compress', False)\n        qpos = root['/observations/qpos'][()]\n        qvel = root['/observations/qvel'][()]\n        action = root['/action'][()]\n        image_dict = dict()"
        },
        {
            "comment": "Iterates through image keys, stores in image_dict.\nChecks if base_action exists and assigns value accordingly.\nIf compressed, un-pads and uncompresses images, stores in image_dict.\nReturns various variables including base_action and image_dict.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/postprocess_episodes.py\":33-59",
            "content": "        for cam_name in root[f'/observations/images/'].keys():\n            image_dict[cam_name] = root[f'/observations/images/{cam_name}'][()]\n        if 'base_action' in root.keys():\n            print('base_action exists')\n            base_action = root['/base_action'][()]\n        else:\n            base_action = None\n        if compressed:\n            compress_len = root['/compress_len'][()]\n    if compressed:\n        for cam_id, cam_name in enumerate(image_dict.keys()):\n            # un-pad and uncompress\n            padded_compressed_image_list = image_dict[cam_name]\n            image_list = []\n            for padded_compressed_image in padded_compressed_image_list: # [:1000] to save memory\n                image = cv2.imdecode(padded_compressed_image, 1)\n                image_list.append(image)\n            image_dict[cam_name] = np.array(image_list)\n    return qpos, qvel, action, base_action, image_dict, is_sim\ndef main(args):\n    dataset_dir = args['dataset_dir']\n    num_episodes = args['num_episodes']\n    start_idx = 0"
        },
        {
            "comment": "This code is part of a function that loads and processes episode data from HDF5 files. It iterates over multiple episodes, concatenating mirrored proprioception and action data, and optionally scales the base action. If any images with 'left_wrist' or 'cam_left_wrist' keys exist in the image dictionary, it swaps their positions for mirroring purposes.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/postprocess_episodes.py\":60-76",
            "content": "    for episode_idx in range(start_idx, start_idx + num_episodes):\n        dataset_name = f'episode_{episode_idx}'\n        qpos, qvel, action, base_action, image_dict, is_sim = load_hdf5(dataset_dir, dataset_name)\n        # process proprioception\n        qpos = np.concatenate([qpos[:, 7:] * MIRROR_STATE_MULTIPLY, qpos[:, :7] * MIRROR_STATE_MULTIPLY], axis=1)\n        qvel = np.concatenate([qvel[:, 7:] * MIRROR_STATE_MULTIPLY, qvel[:, :7] * MIRROR_STATE_MULTIPLY], axis=1)\n        action = np.concatenate([action[:, 7:] * MIRROR_STATE_MULTIPLY, action[:, :7] * MIRROR_STATE_MULTIPLY], axis=1)\n        if base_action is not None:\n            base_action = base_action * MIRROR_BASE_MULTIPLY\n        # mirror image obs\n        if 'left_wrist' in image_dict.keys():\n            image_dict['left_wrist'], image_dict['right_wrist'] = image_dict['right_wrist'][:, :, ::-1], image_dict['left_wrist'][:, :, ::-1]\n        elif 'cam_left_wrist' in image_dict.keys():\n            image_dict['cam_left_wrist'], image_dict['"
        },
        {
            "comment": "This code checks for specific keys in the image_dict and adjusts the values if necessary. If 'left_wrist' or 'cam_left_wrist' is present, it flips the image. It also handles if 'top' or 'cam_high' are present, flipping them accordingly. Then, it creates a data_dict with necessary keys ('/observations/qpos', '/observations/qvel', '/action', and '/base_action') for saving. Finally, it loops through the image_dict to add its contents as key-value pairs in the data_dict, and sets max_timesteps as the length of qpos. The code uses compression while saving.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/postprocess_episodes.py\":76-102",
            "content": "cam_right_wrist'] = image_dict['cam_right_wrist'][:, :, ::-1], image_dict['cam_left_wrist'][:, :, ::-1]\n        else:\n            raise Exception('No left_wrist or cam_left_wrist in image_dict')\n        if 'top' in image_dict.keys():\n            image_dict['top'] = image_dict['top'][:, :, ::-1]\n        elif 'cam_high' in image_dict.keys():\n            image_dict['cam_high'] = image_dict['cam_high'][:, :, ::-1]\n        else:\n            raise Exception('No top or cam_high in image_dict')\n        # saving\n        data_dict = {\n            '/observations/qpos': qpos,\n            '/observations/qvel': qvel,\n            '/action': action,\n            '/base_action': base_action,\n        } if base_action is not None else {\n            '/observations/qpos': qpos,\n            '/observations/qvel': qvel,\n            '/action': action,\n        }\n        for cam_name in image_dict.keys():\n            data_dict[f'/observations/images/{cam_name}'] = image_dict[cam_name]\n        max_timesteps = len(qpos)\n        COMPRESS = True"
        },
        {
            "comment": "This code compresses images using JPEG compression with a quality level of 50, stores the compressed images in the data dictionary, and measures the time taken for the compression process.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/postprocess_episodes.py\":104-124",
            "content": "        if COMPRESS:\n            # JPEG compression\n            t0 = time.time()\n            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 50] # tried as low as 20, seems fine\n            compressed_len = []\n            for cam_name in image_dict.keys():\n                image_list = data_dict[f'/observations/images/{cam_name}']\n                compressed_list = []\n                compressed_len.append([])\n                for image in image_list:\n                    result, encoded_image = cv2.imencode('.jpg', image, encode_param) # 0.02 sec # cv2.imdecode(encoded_image, 1)\n                    compressed_list.append(encoded_image)\n                    compressed_len[-1].append(len(encoded_image))\n                data_dict[f'/observations/images/{cam_name}'] = compressed_list\n            print(f'compression: {time.time() - t0:.2f}s')\n            # pad so it has same length\n            t0 = time.time()\n            compressed_len = np.array(compressed_len)\n            padded_size = compressed_len.max()\n            for cam_name in image_dict.keys():"
        },
        {
            "comment": "This code is padding compressed images, adding them to the data dictionary, and saving the dataset in HDF5 format. The padding ensures all images have the same length for consistency in the HDF5 file. It also records the time taken to pad the images.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/postprocess_episodes.py\":125-142",
            "content": "                compressed_image_list = data_dict[f'/observations/images/{cam_name}']\n                padded_compressed_image_list = []\n                for compressed_image in compressed_image_list:\n                    padded_compressed_image = np.zeros(padded_size, dtype='uint8')\n                    image_len = len(compressed_image)\n                    padded_compressed_image[:image_len] = compressed_image\n                    padded_compressed_image_list.append(padded_compressed_image)\n                data_dict[f'/observations/images/{cam_name}'] = padded_compressed_image_list\n            print(f'padding: {time.time() - t0:.2f}s')\n        # HDF5\n        t0 = time.time()\n        dataset_path = os.path.join(dataset_dir, f'mirror_episode_{episode_idx}')\n        with h5py.File(dataset_path + '.hdf5', 'w', rdcc_nbytes=1024 ** 2 * 2) as root:\n            root.attrs['sim'] = is_sim\n            root.attrs['compress'] = COMPRESS\n            obs = root.create_group('observations')\n            image = obs.create_group('images')"
        },
        {
            "comment": "This code creates datasets for image data and other variables, based on whether to compress or not. It also creates datasets for qpos, qvel, action, and base_action if they are not None. Additionally, it populates the root dataset with data from the data_dict and creates a 'compress_len' dataset if compression is enabled.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/postprocess_episodes.py\":143-161",
            "content": "            for cam_name in image_dict.keys():\n                if COMPRESS:\n                    _ = image.create_dataset(cam_name, (max_timesteps, padded_size), dtype='uint8',\n                                            chunks=(1, padded_size), )\n                else:\n                    _ = image.create_dataset(cam_name, (max_timesteps, 480, 640, 3), dtype='uint8',\n                                            chunks=(1, 480, 640, 3), )\n            qpos = obs.create_dataset('qpos', (max_timesteps, 14))\n            qvel = obs.create_dataset('qvel', (max_timesteps, 14))\n            action = root.create_dataset('action', (max_timesteps, 14))\n            if base_action is not None:\n                base_action = root.create_dataset('base_action', (max_timesteps, 2))\n            for name, array in data_dict.items():\n                root[name][...] = array\n            if COMPRESS:\n                _ = root.create_dataset('compress_len', (len(image_dict.keys()), max_timesteps))\n                root['/compress_len'][...] = compressed_len"
        },
        {
            "comment": "The code snippet saves the dataset, prints the time taken for the process, and has options to save videos and visualize joints. The user is required to specify the dataset directory and the number of episodes.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/postprocess_episodes.py\":163-174",
            "content": "        print(f'Saving {dataset_path}: {time.time() - t0:.1f} secs\\n')\n        if episode_idx == start_idx:\n            save_videos(image_dict, DT, video_path=os.path.join(dataset_dir, dataset_name + '_mirror_video.mp4'))\n            # visualize_joints(qpos, action, plot_path=os.path.join(dataset_dir, dataset_name + '_mirror_qpos.png'))\n            # visualize_timestamp(t_list, dataset_path) # TODO addn timestamp back\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--dataset_dir', action='store', type=str, help='Dataset dir.', required=True)\n    parser.add_argument('--num_episodes', action='store', type=int, help='Number of episodes.', required=True)\n    main(vars(parser.parse_args()))"
        }
    ]
}