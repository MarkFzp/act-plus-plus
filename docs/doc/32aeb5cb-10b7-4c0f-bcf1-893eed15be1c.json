{
    "summary": "The code trains a neural network, visualizes predictions, logs progress, handles exceptions, performs forward/backward passes, updates policy state, saves checkpoints, and sets up data loaders for validation. It plots and saves commanded, observed, and predicted angular speeds for an actuator network, initializes a transformer-based prediction network, calculates MSE loss, normalizes data, and trains the actuator network if necessary.",
    "details": [
        {
            "comment": "This code is importing necessary libraries and defining parameters for training an actuator network. The actuator network takes in observed speed inputs and converts them into desired commanded speeds at test time. It will train the network using specified batch sizes, learning rate, weight decay, number of steps, and save checkpoints periodically.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":1-40",
            "content": "import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nimport os\nimport h5py\nimport math\nimport wandb\nimport pickle\nimport matplotlib.pyplot as plt\nfrom copy import deepcopy\nfrom tqdm import tqdm\nfrom utils import find_all_hdf5\nfrom imitate_episodes import repeater, compute_dict_mean\nimport IPython\ne = IPython.embed\ndef main():\n    ### Idea\n    # input : o o o o o o # observed speed \n    # target: a a a a a a # commanded speed\n    # at test time, input desired speed profile and convert that to command\n    #########################################################\n    history_len = 50\n    future_len = 50\n    prediction_len = 50\n    batch_size_train = 16\n    batch_size_val  = 16\n    lr = 1e-4\n    weight_decay = 1e-4\n    num_steps = 10000\n    validate_every = 2000\n    save_every = 2000\n    expr_name = f'actuator_network_test_{history_len}_{future_len}_{prediction_len}'\n    ckpt_dir = f'/scr/tonyzhao/train_logs/{expr_name}' if os.getlogin() == 'tonyzhao' else f'./ckpts/{expr_name}'"
        },
        {
            "comment": "Code initializes variables, asserts conditions, initializes a wandb project, checks if a directory exists, finds HDF5 files in the dataset directory, calculates train and validation split, and prints information about the data source.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":41-60",
            "content": "    dataset_dir = '/scr/tonyzhao/compressed_datasets/aloha_mobile_fork/' if os.getlogin() == 'tonyzhao' else '/home/zfu/data/aloha_mobile_fork/'\n    #########################################################\n    assert(history_len + future_len >= prediction_len)\n    assert(future_len % prediction_len == 0)\n    wandb.init(project=\"mobile-aloha2\", reinit=True, entity=\"mobile-aloha2\", name=expr_name) # mode='disabled', \n    if not os.path.isdir(ckpt_dir):\n        os.makedirs(ckpt_dir)\n    dataset_path_list = find_all_hdf5(dataset_dir, skip_mirrored_data=True)\n    dataset_path_list = [n for n in dataset_path_list if 'replayed' in n]\n    num_episodes = len(dataset_path_list)\n    # obtain train test split\n    train_ratio = 0.9\n    shuffled_episode_ids = np.random.permutation(num_episodes)\n    train_episode_ids = shuffled_episode_ids[:int(train_ratio * num_episodes)]\n    val_episode_ids = shuffled_episode_ids[int(train_ratio * num_episodes):]\n    print(f'\\n\\nData from: {dataset_dir}\\n- Train on {len(train_episode_ids)} episodes\\n- Test on {len(val_episode_ids)} episodes\\n\\n')"
        },
        {
            "comment": "This code loads normalization stats for qpos and action, either from a file or by calling get_norm_stats function. It then calculates train and val episode lengths based on episode IDs. The code asserts that the all_episode_len is divisible by prediction_len. Next, it saves the dataset stats in a pickle file, constructs train and val datasets using EpisodicDataset class, and utilizes these datasets for further training.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":62-79",
            "content": "    # obtain normalization stats for qpos and action\n    # if load_pretrain:\n    #     with open(os.path.join('/home/zfu/interbotix_ws/src/act/ckpts/pretrain_all', 'dataset_stats.pkl'), 'rb') as f:\n    #         norm_stats = pickle.load(f)\n    #     print('Loaded pretrain dataset stats')\n    norm_stats, all_episode_len = get_norm_stats(dataset_path_list)\n    train_episode_len = [all_episode_len[i] for i in train_episode_ids]\n    val_episode_len = [all_episode_len[i] for i in val_episode_ids]\n    assert(all_episode_len[0] % prediction_len == 0)\n    # save dataset stats\n    stats_path = os.path.join(ckpt_dir, f'actuator_net_stats.pkl')\n    with open(stats_path, 'wb') as f:\n        pickle.dump(norm_stats, f)\n    # construct dataset and dataloader\n    train_dataset = EpisodicDataset(dataset_path_list, norm_stats, train_episode_ids, train_episode_len, history_len, future_len, prediction_len)\n    val_dataset = EpisodicDataset(dataset_path_list, norm_stats, val_episode_ids, val_episode_len, history_len, future_len, prediction_len)"
        },
        {
            "comment": "Creates data loaders for training and validation datasets. Initializes ActuatorNetwork model, optimizer, and prints the number of parameters. Sets initial minimum validation loss and best checkpoint information. Repeats training data loader for iterations. Validates model performance at specified intervals.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":80-101",
            "content": "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True, pin_memory=True, num_workers=1, prefetch_factor=1)\n    val_dataloader = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=True, pin_memory=True, num_workers=1, prefetch_factor=1)\n    policy = ActuatorNetwork(prediction_len).cuda()\n    optimizer = torch.optim.AdamW(policy.parameters(), lr=lr, weight_decay=weight_decay)\n    n_parameters = sum(p.numel() for p in policy.parameters() if p.requires_grad)\n    print(\"number of parameters: %.2fM\" % (n_parameters/1e6,))\n    min_val_loss = np.inf\n    best_ckpt_info = None\n    train_dataloader = repeater(train_dataloader)\n    for step in tqdm(range(num_steps+1)):\n        # validation\n        if step % validate_every == 0:\n            print('validating')\n            with torch.inference_mode():\n                policy.eval()\n                validation_dicts = []\n                for batch_idx, data in enumerate(val_dataloader):\n                    observed_speed, commanded_speed = data"
        },
        {
            "comment": "This code measures the validation loss during training, keeps track of the best validation loss so far, logs the current validation summary to Wandb, and prints out a summary for the current epoch. It also visualizes predictions with a separate function.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":102-120",
            "content": "                    out, forward_dict = policy(observed_speed.cuda(), commanded_speed.cuda())\n                    validation_dicts.append(forward_dict)\n                validation_summary = compute_dict_mean(validation_dicts)\n                epoch_val_loss = validation_summary['loss']\n                if epoch_val_loss < min_val_loss:\n                    min_val_loss = epoch_val_loss\n                    best_ckpt_info = (step, min_val_loss, deepcopy(policy.state_dict()))\n            for k in list(validation_summary.keys()):\n                validation_summary[f'val_{k}'] = validation_summary.pop(k)            \n            wandb.log(validation_summary, step=step)\n            print(f'Val loss:   {epoch_val_loss:.5f}')\n            summary_string = ''\n            for k, v in validation_summary.items():\n                summary_string += f'{k}: {v.item():.3f} '\n            print(summary_string)\n            visualize_prediction(dataset_path_list, val_episode_ids, policy, norm_stats, history_len, future_len, prediction_len, ckpt_dir, step, 'val')"
        },
        {
            "comment": "The code is training an actuator network policy using data from a dataloader. It performs forward and backward passes to calculate loss, updates the policy's state with an optimizer, logs progress to W&B, saves checkpoints at specified intervals, and overwrites the latest checkpoint with the final step of training.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":121-145",
            "content": "            visualize_prediction(dataset_path_list, train_episode_ids, policy, norm_stats, history_len, future_len, prediction_len, ckpt_dir, step, 'train')\n        # training\n        policy.train()\n        optimizer.zero_grad()\n        data = next(train_dataloader)\n        observed_speed, commanded_speed = data\n        out, forward_dict = policy(observed_speed.cuda(), commanded_speed.cuda())\n        # backward\n        loss = forward_dict['loss']\n        loss.backward()\n        optimizer.step()\n        wandb.log(forward_dict, step=step) # not great, make training 1-2% slower\n        if step % save_every == 0:\n            ckpt_path = os.path.join(ckpt_dir, f'actuator_net_step_{step}.ckpt')\n            torch.save(policy.state_dict(), ckpt_path)\n    ckpt_path = os.path.join(ckpt_dir, f'actuator_net_last.ckpt')\n    torch.save(policy.state_dict(), ckpt_path)\n    best_step, min_val_loss, best_state_dict = best_ckpt_info\n    ckpt_path = os.path.join(ckpt_dir, f'actuator_net_step_{best_step}.ckpt')\n    torch.save(best_state_dict, ckpt_path)"
        },
        {
            "comment": "This code segment is responsible for training a neural network and visualizing the predictions. It prints the minimum validation loss and the corresponding step number when training finishes. The visualize_prediction function reads data from a dataset path list, selects episodes for visualization, loads data from HDF5 files, normalizes observed speeds, and provides an unnormalized output function. It also handles potential exceptions during data loading.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":146-166",
            "content": "    print(f'Training finished:\\nval loss {min_val_loss:.6f} at step {best_step}')\ndef visualize_prediction(dataset_path_list, episode_ids, policy, norm_stats, history_len, future_len, prediction_len, ckpt_dir, step, name):\n    num_vis = 2\n    episode_ids = episode_ids[:num_vis]\n    vis_path = [dataset_path_list[i] for i in episode_ids]\n    for i, dataset_path in enumerate(vis_path):\n        try:\n            with h5py.File(dataset_path, 'r') as root:\n                commanded_speed = root['/base_action'][()]\n                observed_speed = root['/obs_tracer'][()]\n        except Exception as ee:\n            print(f'Error loading {dataset_path} in get_norm_stats')\n            print(ee)\n            quit()\n        # commanded_speed = (commanded_speed - norm_stats[\"commanded_speed_mean\"]) / norm_stats[\"commanded_speed_std\"]\n        norm_observed_speed = (observed_speed - norm_stats[\"observed_speed_mean\"]) / norm_stats[\"observed_speed_std\"]\n        out_unnorm_fn = lambda x: (x * norm_stats[\"commanded_speed_std\"]) + norm_stats[\"commanded_speed_mean\"]"
        },
        {
            "comment": "This code segment is preparing input data and feeding it to a neural network policy for prediction. The predicted commanded speed values are then plotted alongside the actual commanded and observed speeds in a plot.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":168-188",
            "content": "        history_pad = np.zeros((history_len, 2))\n        future_pad = np.zeros((future_len, 2))\n        norm_observed_speed = np.concatenate([history_pad, norm_observed_speed, future_pad], axis=0)\n        episode_len = commanded_speed.shape[0]\n        all_pred = []\n        for t in range(0, episode_len, prediction_len):\n            offset_start_ts = t + history_len\n            policy_input = norm_observed_speed[offset_start_ts-history_len: offset_start_ts+future_len]\n            policy_input = torch.from_numpy(policy_input).float().unsqueeze(dim=0).cuda()\n            pred = policy(policy_input)\n            pred = pred.detach().cpu().numpy()[0]\n            all_pred += out_unnorm_fn(pred).tolist()\n        all_pred = np.array(all_pred)\n        plot_path = os.path.join(ckpt_dir, f'{name}{i}_step{step}_linear')\n        plt.figure()\n        plt.plot(commanded_speed[:, 0], label='commanded_speed_linear')\n        plt.plot(observed_speed[:, 0], label='observed_speed_linear')\n        plt.plot(all_pred[:, 0],  label='pred_commanded_speed_linear')"
        },
        {
            "comment": "The code plots the commanded, observed, and predicted angular speeds of an actuator network. It saves the resulting plot in a specified directory. The code also includes vertical dotted lines at regular intervals for visual reference. The ActuatorNetwork class initializes a transformer encoder with a specific number of layers and heads.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":189-216",
            "content": "        # plot vertical grey dotted lines every prediction_len\n        for t in range(0, episode_len, prediction_len):\n            plt.axvline(t, linestyle='--', color='grey')\n        plt.legend()\n        plt.savefig(plot_path)\n        plt.close()\n        plot_path = os.path.join(ckpt_dir, f'{name}{i}_step{step}_angular')\n        plt.figure()\n        plt.plot(commanded_speed[:, 1], label='commanded_speed_angular')\n        plt.plot(observed_speed[:, 1], label='observed_speed_angular')\n        plt.plot(all_pred[:, 1], label='pred_commanded_speed_angular')\n        # plot vertical dotted lines every prediction_len\n        for t in range(0, episode_len, prediction_len):\n            plt.axvline(t, linestyle='--', color='grey')\n        plt.legend()\n        plt.savefig(plot_path)\n        plt.close()\nclass ActuatorNetwork(nn.Module):\n    def __init__(self, prediction_len):\n        super().__init__()\n        d_model = 256\n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=8)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=3)"
        },
        {
            "comment": "This code initializes a network for transformer-based prediction. It includes a PositionalEncoding layer, input and output projection layers, and a prediction length parameter. During training time, it rearranges input data, applies positional encoding, passes through the transformer, and calculates an MSE loss between predicted and target outputs. It returns predicted outputs and loss dictionary.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":217-242",
            "content": "        self.pe = PositionalEncoding(d_model)\n        self.in_proj = nn.Linear(2, d_model)\n        self.out_proj = nn.Linear(d_model, 2)\n        self.prediction_len = prediction_len\n    def forward(self, src, tgt=None):\n        if tgt is not None: # training time\n            # (batch, seq, feature) -> (seq, batch, feature)\n            src = self.in_proj(src)\n            src = torch.einsum('b s d -> s b d', src)\n            src = self.pe(src)\n            out = self.transformer(src)\n            tgt = torch.einsum('b s d -> s b d', tgt)\n            assert(self.prediction_len == tgt.shape[0])\n            out = out[0: self.prediction_len] # take first few tokens only for prediction\n            out = self.out_proj(out)\n            l2_loss = loss = F.mse_loss(out, tgt)\n            loss_dict = {'loss': l2_loss}\n            out = torch.einsum('s b d -> b s d', out)\n            return out, loss_dict\n        else:\n            src = self.in_proj(src)\n            src = torch.einsum('b s d -> s b d', src)\n            src = self.pe(src)"
        },
        {
            "comment": "train_actuator_network.py:243-271 - Applies transformer and positional encoding to source data, extracts the first few tokens for prediction, and then rearranges the output.\nPositionalEncoding - Generates positional encodings of a given size and applies them as an additional dimension in an embedding layer.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":243-271",
            "content": "            out = self.transformer(src)\n            out = out[0: self.prediction_len] # take first few tokens only for prediction\n            out = self.out_proj(out)\n            out = torch.einsum('s b d -> b s d', out)\n            return out\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe = torch.zeros(max_len, 1, d_model)\n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n    def forward(self, x):\n        \"\"\"\n        Arguments:\n            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n        \"\"\"\n        x = x + self.pe[:x.size(0)]\n        return self.dropout(x)\ndef get_norm_stats(dataset_path_list):\n    all_commanded_speed = []"
        },
        {
            "comment": "This code loads and normalizes commanded and observed speed data from multiple datasets. It calculates the mean and standard deviation for both sets of data, clips any outliers in the standard deviation, and stores the normalized data for further analysis or training purposes.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":272-294",
            "content": "    all_observed_speed = []\n    all_episode_len = []\n    for dataset_path in dataset_path_list:\n        try:\n            with h5py.File(dataset_path, 'r') as root:\n                commanded_speed = root['/base_action'][()]\n                observed_speed = root['/obs_tracer'][()]\n        except Exception as e:\n            print(f'Error loading {dataset_path} in get_norm_stats')\n            print(e)\n            quit()\n        all_commanded_speed.append(torch.from_numpy(commanded_speed))\n        all_observed_speed.append(torch.from_numpy(observed_speed))\n        all_episode_len.append(len(commanded_speed))\n    all_commanded_speed = torch.cat(all_commanded_speed, dim=0)\n    all_observed_speed = torch.cat(all_observed_speed, dim=0)\n    # normalize all_commanded_speed\n    commanded_speed_mean = all_commanded_speed.mean(dim=[0]).float()\n    commanded_speed_std = all_commanded_speed.std(dim=[0]).float()\n    commanded_speed_std = torch.clip(commanded_speed_std, 1e-2, np.inf) # clipping\n    # normalize all_observed_speed"
        },
        {
            "comment": "This code calculates the mean and standard deviation of observed speeds, clips the standard deviation to prevent extreme values, and stores these statistics in a dictionary. The dictionary contains the means and standard deviations for both commanded and observed speeds. The code also defines an EpisodicDataset class that initializes with dataset paths, normalization stats, episode IDs, episode lengths, history length, future length, and prediction length.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":295-315",
            "content": "    observed_speed_mean = all_observed_speed.mean(dim=[0]).float()\n    observed_speed_std = all_observed_speed.std(dim=[0]).float()\n    observed_speed_std = torch.clip(observed_speed_std, 1e-2, np.inf) # clipping\n    stats = {\"commanded_speed_mean\": commanded_speed_mean.numpy(), \"commanded_speed_std\": commanded_speed_std.numpy(),\n             \"observed_speed_mean\": observed_speed_mean.numpy(), \"observed_speed_std\": observed_speed_std.numpy()}\n    return stats, all_episode_len\nclass EpisodicDataset(torch.utils.data.Dataset):\n    def __init__(self, dataset_path_list, norm_stats, episode_ids, episode_len, history_len, future_len, prediction_len):\n        super(EpisodicDataset).__init__()\n        self.episode_ids = episode_ids\n        self.dataset_path_list = dataset_path_list\n        self.norm_stats = norm_stats\n        self.episode_len = episode_len\n        self.cumulative_len = np.cumsum(self.episode_len)\n        self.max_episode_len = max(episode_len)\n        self.history_len = history_len\n        self.future_len = future_len"
        },
        {
            "comment": "Initializes attributes and checks if it is a simulation. Returns length based on episode lengths. Locates transition index, finds the dataset path, and reads commanded speed from the HDF5 file.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":316-339",
            "content": "        self.prediction_len = prediction_len\n        self.is_sim = False\n        self.history_pad = np.zeros((self.history_len, 2))\n        self.future_pad = np.zeros((self.future_len, 2))\n        self.prediction_pad = np.zeros((self.prediction_len, 2))\n        self.__getitem__(0) # initialize self.is_sim\n    def __len__(self):\n        return sum(self.episode_len)\n    def _locate_transition(self, index):\n        assert index < self.cumulative_len[-1]\n        episode_index = np.argmax(self.cumulative_len > index) # argmax returns first True index\n        start_ts = index - (self.cumulative_len[episode_index] - self.episode_len[episode_index])\n        episode_id = self.episode_ids[episode_index]\n        return episode_id, start_ts\n    def __getitem__(self, index):\n        episode_id, start_ts = self._locate_transition(index)\n        dataset_path = self.dataset_path_list[episode_id]\n        try:\n            # print(dataset_path)\n            with h5py.File(dataset_path, 'r') as root:\n                commanded_speed = root['/base_action'][()]"
        },
        {
            "comment": "This code is preparing input data for a machine learning model. It concatenates historical and future observations with commanded speeds, adjusts the timestamps, and normalizes the data to have zero mean and unit standard deviation. If there's an error loading the dataset, it prints an error message.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":340-356",
            "content": "                observed_speed = root['/obs_tracer'][()]\n                observed_speed = np.concatenate([self.history_pad, observed_speed, self.future_pad], axis=0)\n                commanded_speed = np.concatenate([commanded_speed, self.prediction_pad], axis=0)\n                offset_start_ts = start_ts + self.history_len\n                commanded_speed = commanded_speed[start_ts: start_ts+self.prediction_len]\n                observed_speed = observed_speed[offset_start_ts-self.history_len: offset_start_ts+self.future_len]\n            commanded_speed = torch.from_numpy(commanded_speed).float()\n            observed_speed = torch.from_numpy(observed_speed).float()\n            # normalize to mean 0 std 1\n            commanded_speed = (commanded_speed - self.norm_stats[\"commanded_speed_mean\"]) / self.norm_stats[\"commanded_speed_std\"]\n            observed_speed = (observed_speed - self.norm_stats[\"observed_speed_mean\"]) / self.norm_stats[\"observed_speed_std\"]\n        except:\n            print(f'Error loading {dataset_path} in __getitem__')"
        },
        {
            "comment": "This code appears to be part of a program that trains an actuator network. It defines a function, possibly for training the actuator network, which may take in image data, joint position data, and other related data, calculates observed and commanded speeds, and returns these values. The code also includes a quit() command and some print statements for debugging purposes. Lastly, there is an if __name__ == '__main__': statement that suggests this code could be executed directly as a main program when the script is run.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/train_actuator_network.py\":357-366",
            "content": "            quit()\n        # print(image_data.dtype, qpos_data.dtype, action_data.dtype, is_pad.dtype)\n        return observed_speed, commanded_speed\nif __name__ == '__main__':\n    main()"
        }
    ]
}