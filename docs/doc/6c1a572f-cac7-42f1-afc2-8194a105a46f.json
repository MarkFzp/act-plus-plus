{
    "summary": "This code defines a bi-manual manipulation environment, sets up action and observation spaces for cube transfer tasks, initializes physics simulation, and enables interactive plotting. It determines rewards based on contact and gripper positions.",
    "details": [
        {
            "comment": "The code imports necessary libraries and defines a function called make_sim_env, which creates a simulation environment for robot bi-manual manipulation with joint position control. The action space consists of left arm joint positions, left gripper position (normalized), right arm joint positions, and right gripper position (normalized).",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":0-25",
            "content": "import numpy as np\nimport os\nimport collections\nimport matplotlib.pyplot as plt\nfrom dm_control import mujoco\nfrom dm_control.rl import control\nfrom dm_control.suite import base\nfrom constants import DT, XML_DIR, START_ARM_POSE\nfrom constants import PUPPET_GRIPPER_POSITION_UNNORMALIZE_FN\nfrom constants import MASTER_GRIPPER_POSITION_NORMALIZE_FN\nfrom constants import PUPPET_GRIPPER_POSITION_NORMALIZE_FN\nfrom constants import PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN\nimport IPython\ne = IPython.embed\nBOX_POSE = [None] # to be changed from outside\ndef make_sim_env(task_name):\n    \"\"\"\n    Environment for simulated robot bi-manual manipulation, with joint position control\n    Action space:      [left_arm_qpos (6),             # absolute joint position\n                        left_gripper_positions (1),    # normalized gripper position (0: close, 1: open)\n                        right_arm_qpos (6),            # absolute joint position\n                        right_gripper_positions (1),]  # normalized gripper position (0: close, 1: open)"
        },
        {
            "comment": "This code defines the observation space for a simulation environment, including joint positions and velocities of both arms and gripper states, along with image input from a camera. It is specific to tasks involving transferring cubes.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":27-37",
            "content": "    Observation space: {\"qpos\": Concat[ left_arm_qpos (6),         # absolute joint position\n                                        left_gripper_position (1),  # normalized gripper position (0: close, 1: open)\n                                        right_arm_qpos (6),         # absolute joint position\n                                        right_gripper_qpos (1)]     # normalized gripper position (0: close, 1: open)\n                        \"qvel\": Concat[ left_arm_qvel (6),         # absolute joint velocity (rad)\n                                        left_gripper_velocity (1),  # normalized gripper velocity (pos: opening, neg: closing)\n                                        right_arm_qvel (6),         # absolute joint velocity (rad)\n                                        right_gripper_qvel (1)]     # normalized gripper velocity (pos: opening, neg: closing)\n                        \"images\": {\"main\": (480x640x3)}        # h, w, c, dtype='uint8'\n    \"\"\"\n    if 'sim_transfer_cube' in task_name:"
        },
        {
            "comment": "The code sets up a bimanual ViperX environment with either a cube transfer or an insertion task. It first defines the XML path for the environment, then initializes physics from the path and a specific task (TransferCubeTask or InsertionTask) depending on the task_name. The Environment class is instantiated with these parameters, including time limit and control timestep. Finally, it returns the environment and initializes BimanualViperXTask which extends base.Task.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":38-60",
            "content": "        xml_path = os.path.join(XML_DIR, f'bimanual_viperx_transfer_cube.xml')\n        physics = mujoco.Physics.from_xml_path(xml_path)\n        task = TransferCubeTask(random=False)\n        env = control.Environment(physics, task, time_limit=20, control_timestep=DT,\n                                  n_sub_steps=None, flat_observation=False)\n    elif 'sim_insertion' in task_name:\n        xml_path = os.path.join(XML_DIR, f'bimanual_viperx_insertion.xml')\n        physics = mujoco.Physics.from_xml_path(xml_path)\n        task = InsertionTask(random=False)\n        env = control.Environment(physics, task, time_limit=20, control_timestep=DT,\n                                  n_sub_steps=None, flat_observation=False)\n    else:\n        raise NotImplementedError\n    return env\nclass BimanualViperXTask(base.Task):\n    def __init__(self, random=None):\n        super().__init__(random=random)\n    def before_step(self, action, physics):\n        left_arm_action = action[:6]\n        right_arm_action = action[7:7+6]\n        normalized_left_gripper_action = action[6]"
        },
        {
            "comment": "This code initializes the environment for each episode and before each step, performing actions on a puppet using gripper positions that are first normalized then unnormalized. The actions involve left and right arm movements as well as full gripper actions. It also retrieves the state of the environment using qpos from physics data.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":61-83",
            "content": "        normalized_right_gripper_action = action[7+6]\n        left_gripper_action = PUPPET_GRIPPER_POSITION_UNNORMALIZE_FN(normalized_left_gripper_action)\n        right_gripper_action = PUPPET_GRIPPER_POSITION_UNNORMALIZE_FN(normalized_right_gripper_action)\n        full_left_gripper_action = [left_gripper_action, -left_gripper_action]\n        full_right_gripper_action = [right_gripper_action, -right_gripper_action]\n        env_action = np.concatenate([left_arm_action, full_left_gripper_action, right_arm_action, full_right_gripper_action])\n        super().before_step(env_action, physics)\n        return\n    def initialize_episode(self, physics):\n        \"\"\"Sets the state of the environment at the start of each episode.\"\"\"\n        super().initialize_episode(physics)\n    @staticmethod\n    def get_qpos(physics):\n        qpos_raw = physics.data.qpos.copy()\n        left_qpos_raw = qpos_raw[:8]\n        right_qpos_raw = qpos_raw[8:16]\n        left_arm_qpos = left_qpos_raw[:6]\n        right_arm_qpos = right_qpos_raw[:6]"
        },
        {
            "comment": "This code defines two methods, `get_qpos` and `get_qvel`, which extract the joint positions and velocities from physics data. The left and right gripper positions and velocities are normalized using `PUPPET_GRIPPER_POSITION_NORMALIZE_FN` and `PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN`. These values are then concatenated into observation arrays 'qpos' and 'qvel', which will be used for the environment state. The `get_env_state` method is not implemented yet, while `get_observation` combines the qpos and qvel observations in an ordered dictionary.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":84-106",
            "content": "        left_gripper_qpos = [PUPPET_GRIPPER_POSITION_NORMALIZE_FN(left_qpos_raw[6])]\n        right_gripper_qpos = [PUPPET_GRIPPER_POSITION_NORMALIZE_FN(right_qpos_raw[6])]\n        return np.concatenate([left_arm_qpos, left_gripper_qpos, right_arm_qpos, right_gripper_qpos])\n    @staticmethod\n    def get_qvel(physics):\n        qvel_raw = physics.data.qvel.copy()\n        left_qvel_raw = qvel_raw[:8]\n        right_qvel_raw = qvel_raw[8:16]\n        left_arm_qvel = left_qvel_raw[:6]\n        right_arm_qvel = right_qvel_raw[:6]\n        left_gripper_qvel = [PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN(left_qvel_raw[6])]\n        right_gripper_qvel = [PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN(right_qvel_raw[6])]\n        return np.concatenate([left_arm_qvel, left_gripper_qvel, right_arm_qvel, right_gripper_qvel])\n    @staticmethod\n    def get_env_state(physics):\n        raise NotImplementedError\n    def get_observation(self, physics):\n        obs = collections.OrderedDict()\n        obs['qpos'] = self.get_qpos(physics)\n        obs['qvel'] = self.get_qvel(physics)"
        },
        {
            "comment": "This code is defining a class `SimEnv` which returns the observation and reward in a bimanual task. It also includes methods for getting the environment state and calculating rewards based on left gripper holding the box. The `TransferCubeTask` inherits from `BimanualViperXTask` and initializes the environment at the start of each episode, with a maximum reward set to 4.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":107-129",
            "content": "        obs['env_state'] = self.get_env_state(physics)\n        obs['images'] = dict()\n        obs['images']['top'] = physics.render(height=480, width=640, camera_id='top')\n        obs['images']['left_wrist'] = physics.render(height=480, width=640, camera_id='left_wrist')\n        obs['images']['right_wrist'] = physics.render(height=480, width=640, camera_id='right_wrist')\n        # obs['images']['angle'] = physics.render(height=480, width=640, camera_id='angle')\n        # obs['images']['vis'] = physics.render(height=480, width=640, camera_id='front_close')\n        return obs\n    def get_reward(self, physics):\n        # return whether left gripper is holding the box\n        raise NotImplementedError\nclass TransferCubeTask(BimanualViperXTask):\n    def __init__(self, random=None):\n        super().__init__(random=random)\n        self.max_reward = 4\n    def initialize_episode(self, physics):\n        \"\"\"Sets the state of the environment at the start of each episode.\"\"\"\n        # TODO Notice: this function does not randomize the env configuration. Instead, set BOX_POSE from outside"
        },
        {
            "comment": "Code resets the arm and box positions, gets the environment state by copying qpos values from 16th index onwards, and calculates the reward based on gripper contact with the box.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":130-153",
            "content": "        # reset qpos, control and box position\n        with physics.reset_context():\n            physics.named.data.qpos[:16] = START_ARM_POSE\n            np.copyto(physics.data.ctrl, START_ARM_POSE)\n            assert BOX_POSE[0] is not None\n            physics.named.data.qpos[-7:] = BOX_POSE[0]\n            # print(f\"{BOX_POSE=}\")\n        super().initialize_episode(physics)\n    @staticmethod\n    def get_env_state(physics):\n        env_state = physics.data.qpos.copy()[16:]\n        return env_state\n    def get_reward(self, physics):\n        # return whether left gripper is holding the box\n        all_contact_pairs = []\n        for i_contact in range(physics.data.ncon):\n            id_geom_1 = physics.data.contact[i_contact].geom1\n            id_geom_2 = physics.data.contact[i_contact].geom2\n            name_geom_1 = physics.model.id2name(id_geom_1, 'geom')\n            name_geom_2 = physics.model.id2name(id_geom_2, 'geom')\n            contact_pair = (name_geom_1, name_geom_2)\n            all_contact_pairs.append(contact_pair)"
        },
        {
            "comment": "This code snippet checks for the contact between different objects and assigns a reward based on those contacts. The 'InsertionTask' class initializes an episode by resetting the qpos, control, and box position. However, it currently does not randomize the environment configuration.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":155-179",
            "content": "        touch_left_gripper = (\"red_box\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs\n        touch_right_gripper = (\"red_box\", \"vx300s_right/10_right_gripper_finger\") in all_contact_pairs\n        touch_table = (\"red_box\", \"table\") in all_contact_pairs\n        reward = 0\n        if touch_right_gripper:\n            reward = 1\n        if touch_right_gripper and not touch_table: # lifted\n            reward = 2\n        if touch_left_gripper: # attempted transfer\n            reward = 3\n        if touch_left_gripper and not touch_table: # successful transfer\n            reward = 4\n        return reward\nclass InsertionTask(BimanualViperXTask):\n    def __init__(self, random=None):\n        super().__init__(random=random)\n        self.max_reward = 4\n    def initialize_episode(self, physics):\n        \"\"\"Sets the state of the environment at the start of each episode.\"\"\"\n        # TODO Notice: this function does not randomize the env configuration. Instead, set BOX_POSE from outside\n        # reset qpos, control and box position"
        },
        {
            "comment": "This code is part of a physics simulation environment setup. It initializes the episode by setting up the arm and box positions, and then defines methods to get the environment state and reward based on contact between objects in the simulation.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":180-204",
            "content": "        with physics.reset_context():\n            physics.named.data.qpos[:16] = START_ARM_POSE\n            np.copyto(physics.data.ctrl, START_ARM_POSE)\n            assert BOX_POSE[0] is not None\n            physics.named.data.qpos[-7*2:] = BOX_POSE[0] # two objects\n            # print(f\"{BOX_POSE=}\")\n        super().initialize_episode(physics)\n    @staticmethod\n    def get_env_state(physics):\n        env_state = physics.data.qpos.copy()[16:]\n        return env_state\n    def get_reward(self, physics):\n        # return whether peg touches the pin\n        all_contact_pairs = []\n        for i_contact in range(physics.data.ncon):\n            id_geom_1 = physics.data.contact[i_contact].geom1\n            id_geom_2 = physics.data.contact[i_contact].geom2\n            name_geom_1 = physics.model.id2name(id_geom_1, 'geom')\n            name_geom_2 = physics.model.id2name(id_geom_2, 'geom')\n            contact_pair = (name_geom_1, name_geom_2)\n            all_contact_pairs.append(contact_pair)\n        touch_right_gripper = (\"red_peg\", \"vx300s_right/10_right_gripper_finger\") in all_contact_pairs"
        },
        {
            "comment": "This code checks if the left gripper finger of vx300s_left is in contact with any of the four sockets, and also verifies if the red peg is touching the table, a socket, or itself. The purpose seems to be detecting specific object interactions in a simulated environment.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":205-217",
            "content": "        touch_left_gripper = (\"socket-1\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs or \\\n                             (\"socket-2\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs or \\\n                             (\"socket-3\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs or \\\n                             (\"socket-4\", \"vx300s_left/10_left_gripper_finger\") in all_contact_pairs\n        peg_touch_table = (\"red_peg\", \"table\") in all_contact_pairs\n        socket_touch_table = (\"socket-1\", \"table\") in all_contact_pairs or \\\n                             (\"socket-2\", \"table\") in all_contact_pairs or \\\n                             (\"socket-3\", \"table\") in all_contact_pairs or \\\n                             (\"socket-4\", \"table\") in all_contact_pairs\n        peg_touch_socket = (\"red_peg\", \"socket-1\") in all_contact_pairs or \\\n                           (\"red_peg\", \"socket-2\") in all_contact_pairs or \\\n                           (\"red_peg\", \"socket-3\") in all_contact_pairs or \\"
        },
        {
            "comment": "The code is defining a function to determine rewards based on contact between different objects and checking gripper positions. It also includes a function for generating action sequences, setting arm joint positions, and normalizing left gripper position.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":218-241",
            "content": "                           (\"red_peg\", \"socket-4\") in all_contact_pairs\n        pin_touched = (\"red_peg\", \"pin\") in all_contact_pairs\n        reward = 0\n        if touch_left_gripper and touch_right_gripper: # touch both\n            reward = 1\n        if touch_left_gripper and touch_right_gripper and (not peg_touch_table) and (not socket_touch_table): # grasp both\n            reward = 2\n        if peg_touch_socket and (not peg_touch_table) and (not socket_touch_table): # peg and socket touching\n            reward = 3\n        if pin_touched: # successful insertion\n            reward = 4\n        return reward\ndef get_action(master_bot_left, master_bot_right):\n    action = np.zeros(14)\n    # arm action\n    action[:6] = master_bot_left.dxl.joint_states.position[:6]\n    action[7:7+6] = master_bot_right.dxl.joint_states.position[:6]\n    # gripper action\n    left_gripper_pos = master_bot_left.dxl.joint_states.position[7]\n    right_gripper_pos = master_bot_right.dxl.joint_states.position[7]\n    normalized_left_pos = MASTER_GRIPPER_POSITION_NORMALIZE_FN(left_gripper_pos)"
        },
        {
            "comment": "This code sets up a teleoperation test in the simulation environment using ALOHA and InterbotixManipulatorXS for left and right arms. It initializes the environment, resets it, and starts an episode by adding the first timestep to the episode list. It also sets up plotting for visualizing the simulation's observation images.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":242-265",
            "content": "    normalized_right_pos = MASTER_GRIPPER_POSITION_NORMALIZE_FN(right_gripper_pos)\n    action[6] = normalized_left_pos\n    action[7+6] = normalized_right_pos\n    return action\ndef test_sim_teleop():\n    \"\"\" Testing teleoperation in sim with ALOHA. Requires hardware and ALOHA repo to work. \"\"\"\n    from interbotix_xs_modules.arm import InterbotixManipulatorXS\n    BOX_POSE[0] = [0.2, 0.5, 0.05, 1, 0, 0, 0]\n    # source of data\n    master_bot_left = InterbotixManipulatorXS(robot_model=\"wx250s\", group_name=\"arm\", gripper_name=\"gripper\",\n                                              robot_name=f'master_left', init_node=True)\n    master_bot_right = InterbotixManipulatorXS(robot_model=\"wx250s\", group_name=\"arm\", gripper_name=\"gripper\",\n                                              robot_name=f'master_right', init_node=False)\n    # setup the environment\n    env = make_sim_env('sim_transfer_cube')\n    ts = env.reset()\n    episode = [ts]\n    # setup plotting\n    ax = plt.subplot()\n    plt_img = ax.imshow(ts.observation['images']['angle'])"
        },
        {
            "comment": "This code enables interactive plotting of the simulation environment's observations and takes input actions for a specific number of time steps. It utilizes matplotlib's `ion()` function to enable interactive plotting, and then iterates through 1000 time steps, getting actions from `get_action` and updating the plot using `plt_img.set_data`. The `test_sim_teleop()` function is called when the script is run directly.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/sim_env.py\":266-278",
            "content": "    plt.ion()\n    for t in range(1000):\n        action = get_action(master_bot_left, master_bot_right)\n        ts = env.step(action)\n        episode.append(ts)\n        plt_img.set_data(ts.observation['images']['angle'])\n        plt.pause(0.02)\nif __name__ == '__main__':\n    test_sim_teleop()"
        }
    ]
}