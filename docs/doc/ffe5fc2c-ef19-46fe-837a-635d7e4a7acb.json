{
    "summary": "The \"plot_logs\" function generates matplotlib plots using training logs, handling missing files and plotting precision-recall curves with interpolated mAP values, setting axes titles and legends.",
    "details": [
        {
            "comment": "This code defines a function \"plot_logs\" that takes in training logs, fields to plot (like class_error, loss), and optional parameters like ewm_col and log_name. It then generates matplotlib plots showing the results of each field color-coded for each log file with solid lines representing training results and dashed lines for test results.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/plot_utils.py\":0-25",
            "content": "\"\"\"\nPlotting utilities to visualize training logs.\n\"\"\"\nimport torch\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pathlib import Path, PurePath\ndef plot_logs(logs, fields=('class_error', 'loss_bbox_unscaled', 'mAP'), ewm_col=0, log_name='log.txt'):\n    '''\n    Function to plot specific fields from training log(s). Plots both training and test results.\n    :: Inputs - logs = list containing Path objects, each pointing to individual dir with a log file\n              - fields = which results to plot from each log file - plots both training and test for each field.\n              - ewm_col = optional, which column to use as the exponential weighted smoothing of the plots\n              - log_name = optional, name of log file if different than default 'log.txt'.\n    :: Outputs - matplotlib plots of results in fields, color coded for each log file.\n               - solid lines are training results, dashed lines are test results.\n    '''\n    func_name = \"plot_utils.py::plot_logs\""
        },
        {
            "comment": "This code checks if the 'logs' argument is a list of Paths or a single Path object. If not, it raises an error. It then iterates over each directory in the logs list and ensures they exist as directories. Finally, it checks if the log_name exists within each directory.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/plot_utils.py\":27-46",
            "content": "    # verify logs is a list of Paths (list[Paths]) or single Pathlib object Path,\n    # convert single Path to list to avoid 'not iterable' error\n    if not isinstance(logs, list):\n        if isinstance(logs, PurePath):\n            logs = [logs]\n            print(f\"{func_name} info: logs param expects a list argument, converted to list[Path].\")\n        else:\n            raise ValueError(f\"{func_name} - invalid argument for logs parameter.\\n \\\n            Expect list[Path] or single Path obj, received {type(logs)}\")\n    # Quality checks - verify valid dir(s), that every item in list is Path object, and that log_name exists in each dir\n    for i, dir in enumerate(logs):\n        if not isinstance(dir, PurePath):\n            raise ValueError(f\"{func_name} - non-Path object in logs argument of {type(dir)}: \\n{dir}\")\n        if not dir.exists():\n            raise ValueError(f\"{func_name} - invalid directory in logs argument:\\n{dir}\")\n        # verify log_name exists\n        fn = Path(dir / log_name)\n        if not fn.exists():"
        },
        {
            "comment": "This code checks for a missing log file and prompts the user to make sure they've reached Epoch 1 in training. It then loads log files, plots data frames for specified fields, and handles missing log files. The plot includes mAP (mean average precision) values using COCO evaluation metrics, and other field values interpolated and smoothed using exponential weighted moving averages.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/plot_utils.py\":47-71",
            "content": "            print(f\"-> missing {log_name}.  Have you gotten to Epoch 1 in training?\")\n            print(f\"--> full path of missing log file: {fn}\")\n            return\n    # load log file(s) and plot\n    dfs = [pd.read_json(Path(p) / log_name, lines=True) for p in logs]\n    fig, axs = plt.subplots(ncols=len(fields), figsize=(16, 5))\n    for df, color in zip(dfs, sns.color_palette(n_colors=len(logs))):\n        for j, field in enumerate(fields):\n            if field == 'mAP':\n                coco_eval = pd.DataFrame(\n                    np.stack(df.test_coco_eval_bbox.dropna().values)[:, 1]\n                ).ewm(com=ewm_col).mean()\n                axs[j].plot(coco_eval, c=color)\n            else:\n                df.interpolate().ewm(com=ewm_col).mean().plot(\n                    y=[f'train_{field}', f'test_{field}'],\n                    ax=axs[j],\n                    color=[color] * 2,\n                    style=['-', '--']\n                )\n    for ax, field in zip(axs, fields):\n        ax.legend([Path(p).name for p in logs])"
        },
        {
            "comment": "The code defines a function plot_precision_recall that takes in files, and depending on the naming_scheme, extracts either the exp_id or stem from each file. It then creates a figure with two subplots and for each file, it loads the corresponding data and calculates precision, recall, and mean average precision (mAP) at 50. The results are printed out for each file in the format \"naming_scheme name: mAP@50=precision%, score=score\".",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/plot_utils.py\":72-96",
            "content": "        ax.set_title(field)\ndef plot_precision_recall(files, naming_scheme='iter'):\n    if naming_scheme == 'exp_id':\n        # name becomes exp_id\n        names = [f.parts[-3] for f in files]\n    elif naming_scheme == 'iter':\n        names = [f.stem for f in files]\n    else:\n        raise ValueError(f'not supported {naming_scheme}')\n    fig, axs = plt.subplots(ncols=2, figsize=(16, 5))\n    for f, color, name in zip(files, sns.color_palette(\"Blues\", n_colors=len(files)), names):\n        data = torch.load(f)\n        # precision is n_iou, n_points, n_cat, n_area, max_det\n        precision = data['precision']\n        recall = data['params'].recThrs\n        scores = data['scores']\n        # take precision for all classes, all areas and 100 detections\n        precision = precision[0, :, :, 0, -1].mean(1)\n        scores = scores[0, :, :, 0, -1].mean(1)\n        prec = precision.mean()\n        rec = data['recall'][0, :, 0, -1].mean()\n        print(f'{naming_scheme} {name}: mAP@50={prec * 100: 05.1f}, ' +\n              f'score={scores.mean():0.3f}, ' +"
        },
        {
            "comment": "This code plots Precision-Recall curves and scores against Recall, sets titles for the axes, adds legends with given names, and returns the figure and axis objects.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/plot_utils.py\":97-106",
            "content": "              f'f1={2 * prec * rec / (prec + rec + 1e-8):0.3f}'\n              )\n        axs[0].plot(recall, precision, c=color)\n        axs[1].plot(recall, scores, c=color)\n    axs[0].set_title('Precision / Recall')\n    axs[0].legend(names)\n    axs[1].set_title('Scores / Recall')\n    axs[1].legend(names)\n    return fig, axs"
        }
    ]
}