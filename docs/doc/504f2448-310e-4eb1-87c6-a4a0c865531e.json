{
    "summary": "This code defines a transformer positional embedding class using sine and cosine encodings for position embeddings. The forward function applies these encodings to the input tensor 'x', normalizing cumulative sums before applying dimensional transformation. This learned absolute position embedding extends nn.Module and is used in transformer models.",
    "details": [
        {
            "comment": "This code defines a positional embedding class for transformers, similar to the one used in the Attention is All You Need paper. It takes in parameters such as num_pos_feats (number of position features), temperature, normalize (whether to normalize or not), and scale. The forward function applies sine and cosine positional encodings to tensor.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/models/position_encoding.py\":0-32",
            "content": "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n\"\"\"\nVarious positional encodings for the transformer.\n\"\"\"\nimport math\nimport torch\nfrom torch import nn\nfrom util.misc import NestedTensor\nimport IPython\ne = IPython.embed\nclass PositionEmbeddingSine(nn.Module):\n    \"\"\"\n    This is a more standard version of the position embedding, very similar to the one\n    used by the Attention is all you need paper, generalized to work on images.\n    \"\"\"\n    def __init__(self, num_pos_feats=64, temperature=10000, normalize=False, scale=None):\n        super().__init__()\n        self.num_pos_feats = num_pos_feats\n        self.temperature = temperature\n        self.normalize = normalize\n        if scale is not None and normalize is False:\n            raise ValueError(\"normalize should be True if scale is passed\")\n        if scale is None:\n            scale = 2 * math.pi\n        self.scale = scale\n    def forward(self, tensor):\n        x = tensor\n        # mask = tensor_list.mask\n        # assert mask is not None"
        },
        {
            "comment": "This code generates position embeddings for a given input tensor 'x'. It first creates not_mask and computes the cumulative sums along rows and columns. Then, it normalizes these sums by dividing them with their respective last elements plus a small epsilon value and multiplies them by a scale factor. The code then calculates a temperature-based dimensional transformation for each element in 'x'. It further computes the sine and cosine of the transformed values, stacks them and flattens them along one dimension. Finally, it concatenates the y and x embeddings along the last dimension, permutes the dimensions, and returns the result. This class extends nn.Module and is used for creating learned absolute position embeddings.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/models/position_encoding.py\":33-56",
            "content": "        # not_mask = ~mask\n        not_mask = torch.ones_like(x[0, [0]])\n        y_embed = not_mask.cumsum(1, dtype=torch.float32)\n        x_embed = not_mask.cumsum(2, dtype=torch.float32)\n        if self.normalize:\n            eps = 1e-6\n            y_embed = y_embed / (y_embed[:, -1:, :] + eps) * self.scale\n            x_embed = x_embed / (x_embed[:, :, -1:] + eps) * self.scale\n        dim_t = torch.arange(self.num_pos_feats, dtype=torch.float32, device=x.device)\n        dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n        pos_x = x_embed[:, :, :, None] / dim_t\n        pos_y = y_embed[:, :, :, None] / dim_t\n        pos_x = torch.stack((pos_x[:, :, :, 0::2].sin(), pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3)\n        pos_y = torch.stack((pos_y[:, :, :, 0::2].sin(), pos_y[:, :, :, 1::2].cos()), dim=4).flatten(3)\n        pos = torch.cat((pos_y, pos_x), dim=3).permute(0, 3, 1, 2)\n        return pos\nclass PositionEmbeddingLearned(nn.Module):\n    \"\"\"\n    Absolute pos embedding, learned."
        },
        {
            "comment": "This code defines a class \"PositionEmbeddingSine\" for creating position encoding using sine and cosine functions. It takes the number of positional features as input and initializes two embedding layers, one for rows and another for columns. The \"forward\" method computes position embeddings by applying row and column embeddings to image indices and returns them. The \"build_position_encoding\" function creates an instance of PositionEmbeddingSine based on the given arguments.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/models/position_encoding.py\":57-86",
            "content": "    \"\"\"\n    def __init__(self, num_pos_feats=256):\n        super().__init__()\n        self.row_embed = nn.Embedding(50, num_pos_feats)\n        self.col_embed = nn.Embedding(50, num_pos_feats)\n        self.reset_parameters()\n    def reset_parameters(self):\n        nn.init.uniform_(self.row_embed.weight)\n        nn.init.uniform_(self.col_embed.weight)\n    def forward(self, tensor_list: NestedTensor):\n        x = tensor_list.tensors\n        h, w = x.shape[-2:]\n        i = torch.arange(w, device=x.device)\n        j = torch.arange(h, device=x.device)\n        x_emb = self.col_embed(i)\n        y_emb = self.row_embed(j)\n        pos = torch.cat([\n            x_emb.unsqueeze(0).repeat(h, 1, 1),\n            y_emb.unsqueeze(1).repeat(1, w, 1),\n        ], dim=-1).permute(2, 0, 1).unsqueeze(0).repeat(x.shape[0], 1, 1, 1)\n        return pos\ndef build_position_encoding(args):\n    N_steps = args.hidden_dim // 2\n    if args.position_embedding in ('v2', 'sine'):\n        # TODO find a better way of exposing other arguments\n        position_embedding = PositionEmbeddingSine(N_steps, normalize=True)"
        },
        {
            "comment": "This code snippet checks the value of 'args.position_embedding' and if it is set to either 'v3' or 'learned', it creates a PositionEmbeddingLearned object. If the input is neither of these, it raises a ValueError with an error message. Finally, it returns the created position embedding object.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/models/position_encoding.py\":87-92",
            "content": "    elif args.position_embedding in ('v3', 'learned'):\n        position_embedding = PositionEmbeddingLearned(N_steps)\n    else:\n        raise ValueError(f\"not supported {args.position_embedding}\")\n    return position_embedding"
        }
    ]
}