{
    "summary": "The code imports libraries, sets parameters, initializes models and preprocesses images for feature extraction. It performs inference, saves features to an HDF5 file, converts tensors to NumPy arrays, and prints the total time taken using argument parser.",
    "details": [
        {
            "comment": "This code imports necessary libraries, defines functions for chunking lists and expanding greyscale images, and sets parameters such as batch size. It also takes command-line arguments for the checkpoint path and dataset directory, extracts relevant information from the checkpoint name, and lists all episode indexes in the dataset.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_cache_feature.py\":0-43",
            "content": "import torch\nimport argparse\nimport pathlib\nfrom torch import nn\nimport torchvision\nimport os\nimport time\nimport h5py\nimport h5py\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nimport cv2\nimport numpy as np\nimport IPython\ne = IPython.embed\ndef chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\ndef expand_greyscale(t):\n    return t.expand(3, -1, -1)\ndef main(args):\n    #################################################\n    batch_size = 256\n    #################################################\n    ckpt_path = args.ckpt_path\n    dataset_dir = args.dataset_dir\n    ckpt_name = pathlib.PurePath(ckpt_path).name\n    dataset_name = ckpt_name.split('-')[1]\n    repr_type = ckpt_name.split('-')[0]\n    seed = int(ckpt_name.split('-')[-1][:-3])\n    if 'cotrain' in ckpt_name:\n        repr_type += '_cotrain'\n    episode_idxs = [int(name.split('_')[1].split('.')[0]) for name in os.listdir(dataset_dir) if ('.hdf5' in name) and ('features' not in name)]"
        },
        {
            "comment": "Loading data and models for each episode, ensuring no holes in the episode indices, and creating feature extractors. The code first checks if there are any existing feature extractors, then loads images and models for each camera name within the dataset, and stores them in a dictionary.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_cache_feature.py\":44-71",
            "content": "    episode_idxs.sort()\n    assert len(episode_idxs) == episode_idxs[-1] + 1 # no holes\n    num_episodes = len(episode_idxs)\n    feature_extractors = {}\n    for episode_idx in range(num_episodes):\n        # load all images\n        print(f'loading data')\n        dataset_path = os.path.join(dataset_dir, f'episode_{episode_idx}.hdf5')\n        with h5py.File(dataset_path, 'r') as root:\n            image_dict = {}\n            camera_names = list(root[f'/observations/images/'].keys())\n            print(f'Camera names: {camera_names}')\n            for cam_name in camera_names:\n                image = root[f'/observations/images/{cam_name}'][:]\n                uncompressed_image = []\n                for im in image:\n                    im = np.array(cv2.imdecode(im, 1))\n                    uncompressed_image.append(im)\n                image = np.stack(uncompressed_image, axis=0)\n                image_dict[cam_name] = image\n        print(f'loading model')\n        # load pretrain nets after cam names are known\n        if not feature_extractors:"
        },
        {
            "comment": "This code initializes a ResNet18 model for each camera name, loads the checkpoint file with the corresponding camera name, modifies the model, and stores it in feature_extractors. Then, it preprocesses images using specified transforms and normalization before passing them to the model for inference.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_cache_feature.py\":72-92",
            "content": "            for cam_name in camera_names:\n                resnet = torchvision.models.resnet18(pretrained=True)\n                loading_status = resnet.load_state_dict(torch.load(ckpt_path.replace('DUMMY', cam_name)))\n                print(cam_name, loading_status)\n                resnet = nn.Sequential(*list(resnet.children())[:-1])\n                resnet = resnet.cuda()\n                resnet.eval()\n                feature_extractors[cam_name] = resnet\n        # inference with resnet\n        feature_dict = {}\n        for cam_name, images in image_dict.items():\n            # Preprocess images\n            image_size = 120 # TODO NOTICE: reduced resolution\n            transform = transforms.Compose([\n                transforms.Resize(image_size),  # will scale the image\n                transforms.CenterCrop(image_size),\n                transforms.ToTensor(),\n                transforms.Lambda(expand_greyscale),\n                transforms.Normalize(\n                    mean=torch.tensor([0.485, 0.456, 0.406]),"
        },
        {
            "comment": "This code processes images, queries a model for features, and stores the extracted features in a dictionary. It uses torch.tensor for standardization, Image.fromarray to convert image to PIL image, transforms images, stacks them, performs inference mode, extracts features from each batch of processed images, concatenates them into all_features list, and finally stores them in feature_dict.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_cache_feature.py\":93-116",
            "content": "                    std=torch.tensor([0.229, 0.224, 0.225])),\n            ])\n            processed_images = []\n            for image in tqdm(images):\n                image = Image.fromarray(image)\n                image = transform(image)\n                processed_images.append(image)\n            processed_images = torch.stack(processed_images).cuda()\n            # query the model\n            all_features = []\n            with torch.inference_mode():\n                for batch in chunks(processed_images, batch_size):\n                    print('inference')\n                    features = feature_extractors[cam_name](batch)\n                    features = features.squeeze(axis=3).squeeze(axis=2)\n                    all_features.append(features)\n            all_features = torch.cat(all_features, axis=0)\n            max_timesteps = all_features.shape[0]\n            feature_dict[cam_name] = all_features\n            # TODO START diagnostics\n            # first_image = images[0]\n            # first_processed_image = processed_images[0].cpu().numpy()"
        },
        {
            "comment": "The code is saving features to an HDF5 file. It creates a group called 'features' within the file and then saves feature data for each camera name in the feature_dict as datasets within the 'features' group. The feature data is converted from PyTorch tensors to NumPy arrays before being saved, and the total time taken to save the features is printed.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_cache_feature.py\":117-141",
            "content": "            # first_feature = all_features[0].cpu().numpy()\n            # import numpy as np\n            # np.save('first_image.npy', first_image)\n            # np.save('first_processed_image.npy', first_processed_image)\n            # np.save('first_feature.npy', first_feature)\n            # torch.save(resnet.state_dict(), 'rn.ckpt')\n            # e()\n            # exit()\n            # TODO END diagnostics\n        # save\n        dataset_path = os.path.join(dataset_dir, f'{repr_type}_features_seed{seed}_episode_{episode_idx}.hdf5')\n        print(dataset_path)\n        # HDF5\n        t0 = time.time()\n        with h5py.File(dataset_path, 'w', rdcc_nbytes=1024 ** 2 * 2) as root:\n            features = root.create_group('features')\n            for cam_name, array in feature_dict.items():\n                cam_feature = features.create_dataset(cam_name, (max_timesteps, 512))\n                features[cam_name][...] = array.cpu().numpy()\n        print(f'Saving: {time.time() - t0:.1f} secs\\n')\nif __name__ == '__main__':"
        },
        {
            "comment": "This code sets up an argument parser, adds arguments for ckpt_path and dataset_dir with necessary types and requirements, and then parses the given arguments to be used in the main function.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/vinn_cache_feature.py\":142-147",
            "content": "    parser = argparse.ArgumentParser(description='cache features')\n    parser.add_argument('--ckpt_path', type=str, required=True, help='ckpt_path')\n    parser.add_argument('--dataset_dir', type=str, required=True, help='dataset_dir')\n    args = parser.parse_args()\n    main(args)"
        }
    ]
}