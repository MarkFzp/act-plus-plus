{
    "summary": "The \"SmoothedValue\" and MetricLogger classes log metrics, offer smoothing, and track progress updates with memory usage. The PyTorch NestedTensor class supports distributed training, ONNX tracing, image padding, and accuracy functions.",
    "details": [
        {
            "comment": "The code is a Python class called \"SmoothedValue\" that tracks a series of values and provides access to smoothed values over a window or the global average. It uses a deque data structure with maximum length \"window_size\" for efficient storage, and keeps track of the total and count of values. The format string \"fmt\" determines how the smoothed value and global average are displayed.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":0-36",
            "content": "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n\"\"\"\nMisc functions, including distributed helpers.\nMostly copy-paste from torchvision references.\n\"\"\"\nimport os\nimport subprocess\nimport time\nfrom collections import defaultdict, deque\nimport datetime\nimport pickle\nfrom packaging import version\nfrom typing import Optional, List\nimport torch\nimport torch.distributed as dist\nfrom torch import Tensor\n# needed due to empty tensor bug in pytorch and torchvision 0.5\nimport torchvision\nif version.parse(torchvision.__version__) < version.parse('0.7'):\n    from torchvision.ops import _new_empty_tensor\n    from torchvision.ops.misc import _output_size\nclass SmoothedValue(object):\n    \"\"\"Track a series of values and provide access to smoothed values over a\n    window or the global series average.\n    \"\"\"\n    def __init__(self, window_size=20, fmt=None):\n        if fmt is None:\n            fmt = \"{median:.4f} ({global_avg:.4f})\"\n        self.deque = deque(maxlen=window_size)\n        self.total = 0.0\n        self.count = 0"
        },
        {
            "comment": "The code defines a class that tracks a deque (double-ended queue) and provides various properties such as median, average, maximum value, global average, and current value. It also allows updating the deque with values and synchronizing counts and totals across multiple processes using PyTorch's distributed functions.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":37-80",
            "content": "        self.fmt = fmt\n    def update(self, value, n=1):\n        self.deque.append(value)\n        self.count += n\n        self.total += value * n\n    def synchronize_between_processes(self):\n        \"\"\"\n        Warning: does not synchronize the deque!\n        \"\"\"\n        if not is_dist_avail_and_initialized():\n            return\n        t = torch.tensor([self.count, self.total], dtype=torch.float64, device='cuda')\n        dist.barrier()\n        dist.all_reduce(t)\n        t = t.tolist()\n        self.count = int(t[0])\n        self.total = t[1]\n    @property\n    def median(self):\n        d = torch.tensor(list(self.deque))\n        return d.median().item()\n    @property\n    def avg(self):\n        d = torch.tensor(list(self.deque), dtype=torch.float32)\n        return d.mean().item()\n    @property\n    def global_avg(self):\n        return self.total / self.count\n    @property\n    def max(self):\n        return max(self.deque)\n    @property\n    def value(self):\n        return self.deque[-1]\n    def __str__(self):\n        return self.fmt.format("
        },
        {
            "comment": "This function runs \"all_gather\" on any picklable data object, not necessarily tensors. It first checks if the world size is 1 and returns data if so. If not, it picks up the data, converts it into a byte tensor, gathers the local size of the tensor from each rank using all_gather, finds the maximum size among them, and finally performs an all_gather on the tensor while padding when necessary.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":81-113",
            "content": "            median=self.median,\n            avg=self.avg,\n            global_avg=self.global_avg,\n            max=self.max,\n            value=self.value)\ndef all_gather(data):\n    \"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors)\n    Args:\n        data: any picklable object\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"\n    world_size = get_world_size()\n    if world_size == 1:\n        return [data]\n    # serialized to a Tensor\n    buffer = pickle.dumps(data)\n    storage = torch.ByteStorage.from_buffer(buffer)\n    tensor = torch.ByteTensor(storage).to(\"cuda\")\n    # obtain Tensor size of each rank\n    local_size = torch.tensor([tensor.numel()], device=\"cuda\")\n    size_list = [torch.tensor([0], device=\"cuda\") for _ in range(world_size)]\n    dist.all_gather(size_list, local_size)\n    size_list = [int(size.item()) for size in size_list]\n    max_size = max(size_list)\n    # receiving Tensor from all ranks\n    # we pad the tensor because torch all_gather does not support"
        },
        {
            "comment": "This code snippet is responsible for gathering tensors of different shapes and reducing the values in a dictionary from all processes. It first creates empty tensors for various sizes, then gathers them using all-gather operation. Afterwards, it converts tensors to data and appends them to a list. The second function reduces the values in an input dictionary across multiple processes by averaging or summing them, based on the specified flag.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":114-142",
            "content": "    # gathering tensors of different shapes\n    tensor_list = []\n    for _ in size_list:\n        tensor_list.append(torch.empty((max_size,), dtype=torch.uint8, device=\"cuda\"))\n    if local_size != max_size:\n        padding = torch.empty(size=(max_size - local_size,), dtype=torch.uint8, device=\"cuda\")\n        tensor = torch.cat((tensor, padding), dim=0)\n    dist.all_gather(tensor_list, tensor)\n    data_list = []\n    for size, tensor in zip(size_list, tensor_list):\n        buffer = tensor.cpu().numpy().tobytes()[:size]\n        data_list.append(pickle.loads(buffer))\n    return data_list\ndef reduce_dict(input_dict, average=True):\n    \"\"\"\n    Args:\n        input_dict (dict): all the values will be reduced\n        average (bool): whether to do average or sum\n    Reduce the values in the dictionary from all processes so that all processes\n    have the averaged results. Returns a dict with the same fields as\n    input_dict, after reduction.\n    \"\"\"\n    world_size = get_world_size()\n    if world_size < 2:\n        return input_dict"
        },
        {
            "comment": "This code snippet defines a class MetricLogger which logs metrics such as average and sum. It also contains a function that averages values across processes, creating a reduced dictionary after performing all-reduce operation. This could be useful for distributed training where different processes need to communicate their results for aggregation and averaging purposes.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":143-175",
            "content": "    with torch.no_grad():\n        names = []\n        values = []\n        # sort the keys so that they are consistent across processes\n        for k in sorted(input_dict.keys()):\n            names.append(k)\n            values.append(input_dict[k])\n        values = torch.stack(values, dim=0)\n        dist.all_reduce(values)\n        if average:\n            values /= world_size\n        reduced_dict = {k: v for k, v in zip(names, values)}\n    return reduced_dict\nclass MetricLogger(object):\n    def __init__(self, delimiter=\"\\t\"):\n        self.meters = defaultdict(SmoothedValue)\n        self.delimiter = delimiter\n    def update(self, **kwargs):\n        for k, v in kwargs.items():\n            if isinstance(v, torch.Tensor):\n                v = v.item()\n            assert isinstance(v, (float, int))\n            self.meters[k].update(v)\n    def __getattr__(self, attr):\n        if attr in self.meters:\n            return self.meters[attr]\n        if attr in self.__dict__:\n            return self.__dict__[attr]\n        raise AttributeError(\"'{}' object has no attribute '{}'\".format("
        },
        {
            "comment": "The code defines a class with methods for logging iterable data every 'print_freq' iterations. It includes synchronization, adding meters, and displaying loss metrics as strings. The class also has a timer to calculate elapsed time for each iteration of the iterable.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":176-207",
            "content": "            type(self).__name__, attr))\n    def __str__(self):\n        loss_str = []\n        for name, meter in self.meters.items():\n            loss_str.append(\n                \"{}: {}\".format(name, str(meter))\n            )\n        return self.delimiter.join(loss_str)\n    def synchronize_between_processes(self):\n        for meter in self.meters.values():\n            meter.synchronize_between_processes()\n    def add_meter(self, name, meter):\n        self.meters[name] = meter\n    def log_every(self, iterable, print_freq, header=None):\n        i = 0\n        if not header:\n            header = ''\n        start_time = time.time()\n        end = time.time()\n        iter_time = SmoothedValue(fmt='{avg:.4f}')\n        data_time = SmoothedValue(fmt='{avg:.4f}')\n        space_fmt = ':' + str(len(str(len(iterable)))) + 'd'\n        if torch.cuda.is_available():\n            log_msg = self.delimiter.join([\n                header,\n                '[{0' + space_fmt + '}/{1}]',\n                'eta: {eta}',\n                '{meters}',"
        },
        {
            "comment": "This code snippet is part of a progress bar implementation. It calculates elapsed time, remaining time estimation, and memory usage for an iterable. The log message is constructed with dynamic placeholders and printed at specified intervals based on the print_freq variable. The CUDA availability check ensures proper printing to the console or CUDA device.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":208-233",
            "content": "                'time: {time}',\n                'data: {data}',\n                'max mem: {memory:.0f}'\n            ])\n        else:\n            log_msg = self.delimiter.join([\n                header,\n                '[{0' + space_fmt + '}/{1}]',\n                'eta: {eta}',\n                '{meters}',\n                'time: {time}',\n                'data: {data}'\n            ])\n        MB = 1024.0 * 1024.0\n        for obj in iterable:\n            data_time.update(time.time() - end)\n            yield obj\n            iter_time.update(time.time() - end)\n            if i % print_freq == 0 or i == len(iterable) - 1:\n                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n                if torch.cuda.is_available():\n                    print(log_msg.format(\n                        i, len(iterable), eta=eta_string,\n                        meters=str(self),\n                        time=str(iter_time), data=str(data_time),"
        },
        {
            "comment": "The code defines a function that calculates the total time taken for an iterable and logs progress updates. It also includes functions to get the current branch, uncommitted changes, and SHA of the current file's directory.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":234-260",
            "content": "                        memory=torch.cuda.max_memory_allocated() / MB))\n                else:\n                    print(log_msg.format(\n                        i, len(iterable), eta=eta_string,\n                        meters=str(self),\n                        time=str(iter_time), data=str(data_time)))\n            i += 1\n            end = time.time()\n        total_time = time.time() - start_time\n        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n        print('{} Total time: {} ({:.4f} s / it)'.format(\n            header, total_time_str, total_time / len(iterable)))\ndef get_sha():\n    cwd = os.path.dirname(os.path.abspath(__file__))\n    def _run(command):\n        return subprocess.check_output(command, cwd=cwd).decode('ascii').strip()\n    sha = 'N/A'\n    diff = \"clean\"\n    branch = 'N/A'\n    try:\n        sha = _run(['git', 'rev-parse', 'HEAD'])\n        subprocess.check_output(['git', 'diff'], cwd=cwd)\n        diff = _run(['git', 'diff-index', 'HEAD'])\n        diff = \"has uncommited changes\" if diff else \"clean\""
        },
        {
            "comment": "This code defines a class NestedTensor, functions collate_fn, _max_by_axis, and _run. NestedTensor represents tensors with optional masking for PyTorch. collate_fn organizes input batches of different dimensions into tuples. _max_by_axis finds the maximum value along an axis in a list of lists. _run executes a git command and returns its output. These functions appear to be used in deep learning tasks, potentially for data processing or model training.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":261-297",
            "content": "        branch = _run(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n    except Exception:\n        pass\n    message = f\"sha: {sha}, status: {diff}, branch: {branch}\"\n    return message\ndef collate_fn(batch):\n    batch = list(zip(*batch))\n    batch[0] = nested_tensor_from_tensor_list(batch[0])\n    return tuple(batch)\ndef _max_by_axis(the_list):\n    # type: (List[List[int]]) -> List[int]\n    maxes = the_list[0]\n    for sublist in the_list[1:]:\n        for index, item in enumerate(sublist):\n            maxes[index] = max(maxes[index], item)\n    return maxes\nclass NestedTensor(object):\n    def __init__(self, tensors, mask: Optional[Tensor]):\n        self.tensors = tensors\n        self.mask = mask\n    def to(self, device):\n        # type: (Device) -> NestedTensor # noqa\n        cast_tensor = self.tensors.to(device)\n        mask = self.mask\n        if mask is not None:\n            assert mask is not None\n            cast_mask = mask.to(device)\n        else:\n            cast_mask = None\n        return NestedTensor(cast_tensor, cast_mask)"
        },
        {
            "comment": "The code defines a `decompose` function that returns tensors and mask, and a `__repr__` function that returns the tensor representation. The main function is `nested_tensor_from_tensor_list`, which takes a list of tensors and creates a nested tensor by resizing them to have the same maximum shape while padding smaller ones. It supports 3D tensors and has TODOs for generalization and supporting different-sized images.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":299-323",
            "content": "    def decompose(self):\n        return self.tensors, self.mask\n    def __repr__(self):\n        return str(self.tensors)\ndef nested_tensor_from_tensor_list(tensor_list: List[Tensor]):\n    # TODO make this more general\n    if tensor_list[0].ndim == 3:\n        if torchvision._is_tracing():\n            # nested_tensor_from_tensor_list() does not export well to ONNX\n            # call _onnx_nested_tensor_from_tensor_list() instead\n            return _onnx_nested_tensor_from_tensor_list(tensor_list)\n        # TODO make it support different-sized images\n        max_size = _max_by_axis([list(img.shape) for img in tensor_list])\n        # min_size = tuple(min(s) for s in zip(*[img.shape for img in tensor_list]))\n        batch_shape = [len(tensor_list)] + max_size\n        b, c, h, w = batch_shape\n        dtype = tensor_list[0].dtype\n        device = tensor_list[0].device\n        tensor = torch.zeros(batch_shape, dtype=dtype, device=device)\n        mask = torch.ones((b, h, w), dtype=torch.bool, device=device)\n        for img, pad_img, m in zip(tensor_list, tensor, mask):"
        },
        {
            "comment": "This code is creating a NestedTensor from a list of tensors. It checks if the input tensor_list has the same size and data type, then pads the images to have the maximum size in each dimension, and sets the mask accordingly. If not supported, it raises a ValueError. This implementation is designed to be compatible with ONNX tracing using @torch.jit.unused decorator.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":324-348",
            "content": "            pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)\n            m[: img.shape[1], :img.shape[2]] = False\n    else:\n        raise ValueError('not supported')\n    return NestedTensor(tensor, mask)\n# _onnx_nested_tensor_from_tensor_list() is an implementation of\n# nested_tensor_from_tensor_list() that is supported by ONNX tracing.\n@torch.jit.unused\ndef _onnx_nested_tensor_from_tensor_list(tensor_list: List[Tensor]) -> NestedTensor:\n    max_size = []\n    for i in range(tensor_list[0].dim()):\n        max_size_i = torch.max(torch.stack([img.shape[i] for img in tensor_list]).to(torch.float32)).to(torch.int64)\n        max_size.append(max_size_i)\n    max_size = tuple(max_size)\n    # work around for\n    # pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)\n    # m[: img.shape[1], :img.shape[2]] = False\n    # which is not yet supported in onnx\n    padded_imgs = []\n    padded_masks = []\n    for img in tensor_list:\n        padding = [(s1 - s2) for s1, s2 in zip(max_size, tuple(img.shape))]"
        },
        {
            "comment": "This code snippet is from the act-plus-plus/detr/util/misc.py file and contains functions to pad images, handle distributed training, and check if distributed training is available and initialized. It also sets up a custom print function for non-master processes in distributed training and returns the world size.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":349-385",
            "content": "        padded_img = torch.nn.functional.pad(img, (0, padding[2], 0, padding[1], 0, padding[0]))\n        padded_imgs.append(padded_img)\n        m = torch.zeros_like(img[0], dtype=torch.int, device=img.device)\n        padded_mask = torch.nn.functional.pad(m, (0, padding[2], 0, padding[1]), \"constant\", 1)\n        padded_masks.append(padded_mask.to(torch.bool))\n    tensor = torch.stack(padded_imgs)\n    mask = torch.stack(padded_masks)\n    return NestedTensor(tensor, mask=mask)\ndef setup_for_distributed(is_master):\n    \"\"\"\n    This function disables printing when not in master process\n    \"\"\"\n    import builtins as __builtin__\n    builtin_print = __builtin__.print\n    def print(*args, **kwargs):\n        force = kwargs.pop('force', False)\n        if is_master or force:\n            builtin_print(*args, **kwargs)\n    __builtin__.print = print\ndef is_dist_avail_and_initialized():\n    if not dist.is_available():\n        return False\n    if not dist.is_initialized():\n        return False\n    return True\ndef get_world_size():"
        },
        {
            "comment": "This code sets up distributed mode for deep learning tasks. It checks if the distribution environment is available and initialized, then gets world size and rank, defines helper functions like saving on master process only, and initializes distributed mode based on the environment variables. The code assumes the use of either Torch or NCCL backend for distributed training.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":386-424",
            "content": "    if not is_dist_avail_and_initialized():\n        return 1\n    return dist.get_world_size()\ndef get_rank():\n    if not is_dist_avail_and_initialized():\n        return 0\n    return dist.get_rank()\ndef is_main_process():\n    return get_rank() == 0\ndef save_on_master(*args, **kwargs):\n    if is_main_process():\n        torch.save(*args, **kwargs)\ndef init_distributed_mode(args):\n    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n        args.rank = int(os.environ[\"RANK\"])\n        args.world_size = int(os.environ['WORLD_SIZE'])\n        args.gpu = int(os.environ['LOCAL_RANK'])\n    elif 'SLURM_PROCID' in os.environ:\n        args.rank = int(os.environ['SLURM_PROCID'])\n        args.gpu = args.rank % torch.cuda.device_count()\n    else:\n        print('Not using distributed mode')\n        args.distributed = False\n        return\n    args.distributed = True\n    torch.cuda.set_device(args.gpu)\n    args.dist_backend = 'nccl'\n    print('| distributed init (rank {}): {}'.format(\n        args.rank, args.dist_url), flush=True)"
        },
        {
            "comment": "This code initializes a distributed process group and sets up functions for calculating accuracy and interpolating tensors. The distributed process group allows for parallel processing across multiple devices, while the accuracy function computes precision@k for specified values of k, and the interpolate function provides equivalent functionality to nn.functional.interpolate but supports empty batch sizes.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":425-453",
            "content": "    torch.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                         world_size=args.world_size, rank=args.rank)\n    torch.distributed.barrier()\n    setup_for_distributed(args.rank == 0)\n@torch.no_grad()\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    if target.numel() == 0:\n        return [torch.zeros([], device=output.device)]\n    maxk = max(topk)\n    batch_size = target.size(0)\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\ndef interpolate(input, size=None, scale_factor=None, mode=\"nearest\", align_corners=None):\n    # type: (Tensor, Optional[List[int]], Optional[float], str, Optional[bool]) -> Tensor\n    \"\"\"\n    Equivalent to nn.functional.interpolate, but with support for empty batch sizes."
        },
        {
            "comment": "This function checks the PyTorch and torchvision versions, and performs interpolation differently based on the version. If the version is below 0.7, it uses torch.nn.functional.interpolate(). Otherwise, it calls torchvision.ops.misc.interpolate(). The code also handles empty input cases by returning a new tensor with the appropriate shape.",
            "location": "\"/media/root/Prima/works/act-plus-plus/docs/src/detr/util/misc.py\":454-467",
            "content": "    This will eventually be supported natively by PyTorch, and this\n    class can go away.\n    \"\"\"\n    if version.parse(torchvision.__version__) < version.parse('0.7'):\n        if input.numel() > 0:\n            return torch.nn.functional.interpolate(\n                input, size, scale_factor, mode, align_corners\n            )\n        output_shape = _output_size(2, input, size, scale_factor)\n        output_shape = list(input.shape[:-2]) + list(output_shape)\n        return _new_empty_tensor(input, output_shape)\n    else:\n        return torchvision.ops.misc.interpolate(input, size, scale_factor, mode, align_corners)"
        }
    ]
}